{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <h1>Assignment 7</h1> </center>\n",
    "<center> <h1>EIN 4933/6935 Python for Data Science Summer 2020</h1> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will evaluate a number of models using a data set from this <a href=\"http://archive.ics.uci.edu/ml/datasets.php\">web-site</a>.\n",
    "\n",
    "The data set that you choose must satisfy the following conditions:<br/>\n",
    "**Attribute Characteristics** (i.e. features data type): Categorical and Numerical (i.e. Integer and/or Real)<br/>\n",
    "**Associated Tasks** (i.e. prediction problem): Classification or Regression<br/>\n",
    "**Number of Attributes** (i.e. features): >=10<br/>\n",
    "**Number of Instances** (# of rows): >= 1000<br/>\n",
    "**Missing Values?:** Yes <br/>\n",
    "\n",
    "For example, <a href=\"http://archive.ics.uci.edu/ml/datasets/Adult\">Adults Data Set</a> satifies the given conditions. In most cases, the data values and the set of features/response variable names are stored in different data sources. For Adults Data Set, the data values and features/response variables are located in *adult.data* and *adult.names*, respectively. You can download each files by clicking Data Folder in the given <a href=\"http://archive.ics.uci.edu/ml/datasets/Adult\">link</a>.\n",
    "\n",
    "Use the data set that you choose to answer the questions below. You can create as many cells as you desire for all solutions.<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "1) Choose and download a data set from the <a href=\"http://archive.ics.uci.edu/ml/datasets.php\">link</a>. Make sure the set satisfies the above given conditions. Please note you will have to download both **.data** and **.names** files given in Data Folder web-page.<br/> \n",
    "2) Change the data values file from .data to .csv extension. This will be the csv file that you will use. This includes both data values and features/response variable names (i.e. header). For example, you can open .names file with a text editor (manually) and copy the features/response names. Or you can choose to read those names with a code.   \n",
    "3) Read the data into a dataframe from csv file that you prepare in Question 2.<br/>\n",
    "4) Remove any irrelevant data columns from the dataframe. If there are any missing values in the dataset, they should be replaced through a data imputation method. Any missing rows should be deleted from the dataset. Each column data type must be converted into an appropriate data type. The data types can be obtained either in .names info file.<br/>\n",
    "5) Perform the following preprocessing (Feature Extraction) tasks:\n",
    "a) Normalize the **numerical features** by using `MinMaxScaler` built-in function in scikit-learn package.\n",
    "b) Use a One-Hot Encoder method to encode **categorical features**. You can use `get_dummies()` from Pandas Package or `DictVectorizer()` from Scikit-Learn Package or any other built-in function that you are familiar with.<br/>\n",
    "6) Create two dataframes: response and features. Split these dataframes into train and test parts.<br/>\n",
    "7) You will evaluate a number of models.<br/> \n",
    "a) Choose at least 3 different models from the following list:<br/>\n",
    "Multiple Linear Regression, Decision Trees, Random Forest, Logistic Regression, Extreme Gradient Boosting, Categorical Gradient Boosting, Light Gradient Boosting Model, Support Vector Machines, Na√Øve Bayes, Nearest Neighbor or any other model that you are familiary with. All these models have built-in function available in scikit-learn package. We have covered many of them in the lectures. Make sure to use the correct model function (classifier or regressor) for your prediction problem.<br/>\n",
    "In your model evaluation, make sure to follow the following steps:<br/>\n",
    "b) Train the models using train part of the data.<br/>\n",
    "c) Generate predictions over the test data.<br/>\n",
    "d) Calculate the associated metrics (accuracy for classification problem and MAE, MSE and RMSE for regression problem) over test data by calling a built-in function from scikit learn package. <br/>\n",
    "e) Report the estimated metrics in a table for each model. <br/>\n",
    "8) Report the feature importance results of the best model.<br/> \n",
    "a) Create a dataframe that has two columns: one for the name of the feature and one for the associated score. Make sure to report overall feature importance of each feature. (i.e. not for each label). You can aggregate using mean of importance values reported for each label. <br/>\n",
    "b) Report feature importance in a bar chart. <br/>\n",
    "9) Drop at least 3 least importance features. Re-train your best model and evaluate your model by repeating the steps (b)-(e) in Question-7.<br/> \n",
    "10) Perform hyperparameter tuning with grid search for your best model. For example, the following code allows you to tune the hyperparameters of a decision tree model. The function returns the tuned parameters. You can use the same function by adjusting it for your best model. The candiate hyperparameters to be tuned can be obtained by calling `help` funciton in Python. For this specific example, you can call `help(DecisionTreeClassifier)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "def grid_search(X, y, kfolds):\n",
    "    \n",
    "    #create a dictionary of all values we want to test\n",
    "    param_grid = {'criterion':['gini','entropy'], 'max_depth': np.arange(3, 15)}\n",
    "    # decision tree model\n",
    "    dtree_model=DecisionTreeClassifier()\n",
    "    #use gridsearch to test all values\n",
    "    dtree_gscv = GridSearchCV(dtree_model, param_grid, cv=kfolds)\n",
    "    #fit model to data\n",
    "    dtree_gscv.fit(X, y)\n",
    "    return dtree_gscv.best_params_\n",
    "\n",
    "grid_search(X = features_train, y = response_train, kfolds = 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
