{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <h1>Assignment 7</h1> </center>\n",
    "<center> <h1>EIN 4933/6935 Python for Data Science Summer 2020</h1> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will evaluate a number of models using a data set from this <a href=\"http://archive.ics.uci.edu/ml/datasets.php\">web-site</a>.\n",
    "\n",
    "The data set that you choose must satisfy the following conditions:<br/>\n",
    "**Attribute Characteristics** (i.e. features data type): Categorical and Numerical (i.e. Integer and/or Real)<br/>\n",
    "**Associated Tasks** (i.e. prediction problem): Classification or Regression<br/>\n",
    "**Number of Attributes** (i.e. features): >=10<br/>\n",
    "**Number of Instances** (# of rows): >= 1000<br/>\n",
    "**Missing Values?:** Yes <br/>\n",
    "\n",
    "For example, <a href=\"http://archive.ics.uci.edu/ml/datasets/Adult\">Adults Data Set</a> satifies the given conditions. In most cases, the data values and the set of features/response variable names are stored in different data sources. For Adults Data Set, the data values and features/response variables are located in *adult.data* and *adult.names*, respectively. You can download each files by clicking Data Folder in the given <a href=\"http://archive.ics.uci.edu/ml/datasets/Adult\">link</a>.\n",
    "\n",
    "Use the data set that you choose to answer the questions below. You can create as many cells as you desire for all solutions.<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "1) Choose and download a data set from the <a href=\"http://archive.ics.uci.edu/ml/datasets.php\">link</a>. Make sure the set satisfies the above given conditions. Please note you will have to download both **.data** and **.names** files given in Data Folder web-page.<br/> \n",
    "2) Change the data values file from .data to .csv extension. This will be the csv file that you will use. This includes both data values and features/response variable names (i.e. header). For example, you can open .names file with a text editor (manually) and copy the features/response names. Or you can choose to read those names with a code.   \n",
    "3) Read the data into a dataframe from csv file that you prepare in Question 2.<br/>\n",
    "4) Remove any irrelevant data columns from the dataframe. If there are any missing values in the dataset, they should be replaced through a data imputation method. Any missing rows should be deleted from the dataset. Each column data type must be converted into an appropriate data type. The data types can be obtained either in .names info file.<br/>\n",
    "5) Perform the following preprocessing (Feature Extraction) tasks:\n",
    "a) Normalize the **numerical features** by using `MinMaxScaler` built-in function in scikit-learn package.\n",
    "b) Use a One-Hot Encoder method to encode **categorical features**. You can use `get_dummies()` from Pandas Package or `DictVectorizer()` from Scikit-Learn Package or any other built-in function that you are familiar with.<br/>\n",
    "6) Create two dataframes: response and features. Split these dataframes into train and test parts.<br/>\n",
    "7) You will evaluate a number of models.<br/> \n",
    "a) Choose at least 3 different models from the following list:<br/>\n",
    "Multiple Linear Regression, Decision Trees, Random Forest, Logistic Regression, Extreme Gradient Boosting, Categorical Gradient Boosting, Light Gradient Boosting Model, Support Vector Machines, Na√Øve Bayes, Nearest Neighbor or any other model that you are familiary with. All these models have built-in function available in scikit-learn package. We have covered many of them in the lectures. Make sure to use the correct model function (classifier or regressor) for your prediction problem.<br/>\n",
    "In your model evaluation, make sure to follow the following steps:<br/>\n",
    "b) Train the models using train part of the data.<br/>\n",
    "c) Generate predictions over the test data.<br/>\n",
    "d) Calculate the associated metrics (accuracy for classification problem and MAE, MSE and RMSE for regression problem) over test data by calling a built-in function from scikit learn package. <br/>\n",
    "e) Report the estimated metrics in a table for each model. <br/>\n",
    "8) Report the feature importance results of the best model.<br/> \n",
    "a) Create a dataframe that has two columns: one for the name of the feature and one for the associated score. Make sure to report overall feature importance of each feature. (i.e. not for each label). You can aggregate using mean of importance values reported for each label. <br/>\n",
    "b) Report feature importance in a bar chart. <br/>\n",
    "9) Drop at least 3 least importance features. Re-train your best model and evaluate your model by repeating the steps (b)-(e) in Question-7.<br/> \n",
    "10) Perform hyperparameter tuning with grid search for your best model. For example, the following code allows you to tune the hyperparameters of a decision tree model. The function returns the tuned parameters. You can use the same function by adjusting it for your best model. The candiate hyperparameters to be tuned can be obtained by calling `help` funciton in Python. For this specific example, you can call `help(DecisionTreeClassifier)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Choose and download a data set \n",
    "\n",
    "I chose the [`Bike Sharing`](http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset) dataset\n",
    "\n",
    "It satisfies the following conditions:  \n",
    "\n",
    "* *Attribute Characteristics:* Numerical and Categorical (e.g. `holiday`, `season`, `workingday`, `weathersit`)  \n",
    "* *Associated Tasks:* Regression  \n",
    "* *Number of Attributes:* 13 (>10)  \n",
    "* *Number of Instances:* 17379 (>1000)  \n",
    "* *Missing Values?:* ~Yes~ *No* (disregard one of the constraints)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Change the data values file from .data to .csv extension. \n",
    "\n",
    "The Bike Share dataset is already in `.csv` format\n",
    "\n",
    "## 3) Read the data into a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0896</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "5        6  2011-01-01       1   0     1   5        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81     0.0000       3          13   16  \n",
       "1           1  0.22  0.2727  0.80     0.0000       8          32   40  \n",
       "2           1  0.22  0.2727  0.80     0.0000       5          27   32  \n",
       "3           1  0.24  0.2879  0.75     0.0000       3          10   13  \n",
       "4           1  0.24  0.2879  0.75     0.0000       0           1    1  \n",
       "5           2  0.24  0.2576  0.75     0.0896       0           1    1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../data/Bike-Sharing-Dataset/hour.csv\")\n",
    "\n",
    "data.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Remove any irrelevant data columns from the dataframe. \n",
    "\n",
    "Each column data type must be converted into an appropriate data type. For this dataset, all columns with data type 'int' are categorical!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I will drop `instant` because it is a record index \n",
    "* I will keep only the day of the month from the `dteday` (date) column as a categorical variable between 1-31. Month and year columns are already accounted for.\n",
    "* I will drop `casual` and `registered` because they are just counts of the casual users and registered users, and with this information the total count could be predicted by just summing the two values. \n",
    "    - They could also be response variables if I was interested in predicting only casual users or only registered users.\n",
    "* I will keep all other attributes for now.  \n",
    "\n",
    "There is no missing data to impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instant       0\n",
       "dteday        0\n",
       "season        0\n",
       "yr            0\n",
       "mnth          0\n",
       "hr            0\n",
       "holiday       0\n",
       "weekday       0\n",
       "workingday    0\n",
       "weathersit    0\n",
       "temp          0\n",
       "atemp         0\n",
       "hum           0\n",
       "windspeed     0\n",
       "casual        0\n",
       "registered    0\n",
       "cnt           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>day</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17374</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17375</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17376</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17377</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17378</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       season  yr  mnth  day  hr  holiday  weekday  workingday  weathersit  \\\n",
       "17374       1   1    12   31  19        0        1           1           2   \n",
       "17375       1   1    12   31  20        0        1           1           2   \n",
       "17376       1   1    12   31  21        0        1           1           1   \n",
       "17377       1   1    12   31  22        0        1           1           1   \n",
       "17378       1   1    12   31  23        0        1           1           1   \n",
       "\n",
       "       temp   atemp   hum  windspeed  cnt  \n",
       "17374  0.26  0.2576  0.60     0.1642  119  \n",
       "17375  0.26  0.2576  0.60     0.1642   89  \n",
       "17376  0.26  0.2576  0.60     0.1642   90  \n",
       "17377  0.26  0.2727  0.56     0.1343   61  \n",
       "17378  0.26  0.2727  0.65     0.1343   49  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a new clean df to work with\n",
    "df_clean = data.drop(['instant','casual','registered'] ,axis=1)\n",
    "\n",
    "# create a new column with just the day value and drop 'dteday'\n",
    "df_clean.insert(4, \"day\", df_clean['dteday'].str[-2:].astype('int64'))\n",
    "\n",
    "df_clean.drop('dteday', axis=1, inplace=True)\n",
    "df_clean.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17379 entries, 0 to 17378\n",
      "Data columns (total 14 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   season      17379 non-null  int64  \n",
      " 1   yr          17379 non-null  int64  \n",
      " 2   mnth        17379 non-null  int64  \n",
      " 3   day         17379 non-null  int64  \n",
      " 4   hr          17379 non-null  int64  \n",
      " 5   holiday     17379 non-null  int64  \n",
      " 6   weekday     17379 non-null  int64  \n",
      " 7   workingday  17379 non-null  int64  \n",
      " 8   weathersit  17379 non-null  int64  \n",
      " 9   temp        17379 non-null  float64\n",
      " 10  atemp       17379 non-null  float64\n",
      " 11  hum         17379 non-null  float64\n",
      " 12  windspeed   17379 non-null  float64\n",
      " 13  cnt         17379 non-null  int64  \n",
      "dtypes: float64(4), int64(10)\n",
      "memory usage: 1.9 MB\n"
     ]
    }
   ],
   "source": [
    "# Note: all columns with data type 'int' are categorical!\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Perform the following preprocessing (Feature Extraction) tasks:\n",
    "* My **numerical features** are `temp`,`atemp`,`hum`, and `windspeed` and they have already been normalized.\n",
    "* Use a One-Hot Encoder method to encode **categorical features**. I use `get_dummies()` from Pandas Package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['season', 'yr', 'mnth', 'day', 'hr', 'holiday', 'weekday', 'workingday',\n",
       "       'weathersit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = df_clean['cnt']\n",
    "features = df_clean.drop('cnt', axis=1)\n",
    "\n",
    "# select columns with numerical features\n",
    "num_cols = features.select_dtypes(include=['float16', 'float32', 'float64']).columns\n",
    "\n",
    "# select columns categorical features\n",
    "# Note: all columns with data type 'int' are categorical\n",
    "cat_cols = features.select_dtypes(include=['int16', 'int32', 'int64']).columns\n",
    "\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cat = features.copy()\n",
    "\n",
    "# create dummy variables for all categorical variables\n",
    "features_cat[cat_cols] = features_cat[cat_cols].astype('category')\n",
    "\n",
    "features_encoded = pd.get_dummies(features_cat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17379, 92)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>season_1</th>\n",
       "      <th>season_2</th>\n",
       "      <th>season_3</th>\n",
       "      <th>season_4</th>\n",
       "      <th>yr_0</th>\n",
       "      <th>yr_1</th>\n",
       "      <th>...</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>weekday_4</th>\n",
       "      <th>weekday_5</th>\n",
       "      <th>weekday_6</th>\n",
       "      <th>workingday_0</th>\n",
       "      <th>workingday_1</th>\n",
       "      <th>weathersit_1</th>\n",
       "      <th>weathersit_2</th>\n",
       "      <th>weathersit_3</th>\n",
       "      <th>weathersit_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   temp   atemp   hum  windspeed  season_1  season_2  season_3  season_4  \\\n",
       "0  0.24  0.2879  0.81        0.0         1         0         0         0   \n",
       "1  0.22  0.2727  0.80        0.0         1         0         0         0   \n",
       "2  0.22  0.2727  0.80        0.0         1         0         0         0   \n",
       "3  0.24  0.2879  0.75        0.0         1         0         0         0   \n",
       "4  0.24  0.2879  0.75        0.0         1         0         0         0   \n",
       "\n",
       "   yr_0  yr_1  ...  weekday_3  weekday_4  weekday_5  weekday_6  workingday_0  \\\n",
       "0     1     0  ...          0          0          0          1             1   \n",
       "1     1     0  ...          0          0          0          1             1   \n",
       "2     1     0  ...          0          0          0          1             1   \n",
       "3     1     0  ...          0          0          0          1             1   \n",
       "4     1     0  ...          0          0          0          1             1   \n",
       "\n",
       "   workingday_1  weathersit_1  weathersit_2  weathersit_3  weathersit_4  \n",
       "0             0             1             0             0             0  \n",
       "1             0             1             0             0             0  \n",
       "2             0             1             0             0             0  \n",
       "3             0             1             0             0             0  \n",
       "4             0             1             0             0             0  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(features_encoded.shape)\n",
    "features_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17379, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>day</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  yr  mnth  day  hr  holiday  weekday  workingday  weathersit  temp  \\\n",
       "0       1   0     1    1   0        0        6           0           1  0.24   \n",
       "1       1   0     1    1   1        0        6           0           1  0.22   \n",
       "2       1   0     1    1   2        0        6           0           1  0.22   \n",
       "3       1   0     1    1   3        0        6           0           1  0.24   \n",
       "4       1   0     1    1   4        0        6           0           1  0.24   \n",
       "\n",
       "    atemp   hum  windspeed  \n",
       "0  0.2879  0.81        0.0  \n",
       "1  0.2727  0.80        0.0  \n",
       "2  0.2727  0.80        0.0  \n",
       "3  0.2879  0.75        0.0  \n",
       "4  0.2879  0.75        0.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(features.shape)\n",
    "features.head()  # still unchanged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Create response and features dataframes. \n",
    "Split these dataframes into **train** and **test** parts.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "result_list = train_test_split(features, response, test_size=0.20, random_state=9)\n",
    "features_train, features_test, response_train, response_test = result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) You will evaluate a number of models.   \n",
    "a) Choose at least 3 different models from the following list:  \n",
    "Multiple Linear Regression, Decision Trees, Random Forest, Logistic Regression, Extreme Gradient Boosting, Categorical Gradient Boosting, Light Gradient Boosting Model, Support Vector Machines, Na√Øve Bayes, Nearest Neighbor or any other model that you are familiary with. All these models have built-in function available in scikit-learn package. We have covered many of them in the lectures. Make sure to use the correct model function (classifier or regressor) for your prediction problem.  \n",
    "\n",
    "In your model evaluation, make sure to follow the following steps:  \n",
    "b) Train the models using train part of the data.  \n",
    "c) Generate predictions over the test data.  \n",
    "d) Calculate the associated metrics (accuracy for classification problem and MAE, MSE and RMSE for regression problem) over test data by calling a built-in function from scikit learn package.   \n",
    "e) Report the estimated metrics in a table for each model.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>33.1715</td>\n",
       "      <td>3047.8113</td>\n",
       "      <td>55.2070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>24.5175</td>\n",
       "      <td>1622.2501</td>\n",
       "      <td>40.2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extreme Gradient Boosting</td>\n",
       "      <td>24.8283</td>\n",
       "      <td>1556.0796</td>\n",
       "      <td>39.4472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Categorical Gradient Boosting</td>\n",
       "      <td>23.5424</td>\n",
       "      <td>1463.6305</td>\n",
       "      <td>38.2574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Light Gradient Boosting Model</td>\n",
       "      <td>25.6562</td>\n",
       "      <td>1674.7163</td>\n",
       "      <td>40.9233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model Name      MAE        MSE     RMSE\n",
       "0                  Decision Tree  33.1715  3047.8113  55.2070\n",
       "1                  Random Forest  24.5175  1622.2501  40.2772\n",
       "2      Extreme Gradient Boosting  24.8283  1556.0796  39.4472\n",
       "3  Categorical Gradient Boosting  23.5424  1463.6305  38.2574\n",
       "4  Light Gradient Boosting Model  25.6562  1674.7163  40.9233"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn import metrics\n",
    "\n",
    "# a) Choose models\n",
    "models_list = [DecisionTreeRegressor(),\n",
    "               RandomForestRegressor(), \n",
    "               XGBRegressor(), \n",
    "               CatBoostRegressor(silent=True),\n",
    "               LGBMRegressor()] # removed LinearRegression(),\n",
    "\n",
    "# model names in a list\n",
    "model_names = ['Decision Tree', \n",
    "               'Random Forest', \n",
    "               'Extreme Gradient Boosting', \n",
    "               'Categorical Gradient Boosting',\n",
    "               'Light Gradient Boosting Model']  # removed 'Linear Regression',\n",
    "\n",
    "\n",
    "feature_names = features.columns.to_list()\n",
    "feature_importance_df = pd.DataFrame(feature_names, columns=['features'])\n",
    "MAE_list = []\n",
    "MSE_list = []\n",
    "RMSE_list = []\n",
    "\n",
    "for model in range(len(models_list)):\n",
    "    regressor = models_list[model]\n",
    "    # b) Train the models using train part of the data\n",
    "    regressor.fit(features_train, response_train)\n",
    "    # c) Generate predictions over the test data\n",
    "    response_pred = regressor.predict(features_test)\n",
    "    # d) Calculate the associated metrics \n",
    "    MAE_list.append(round(metrics.mean_absolute_error(response_test, response_pred), 4))\n",
    "    MSE_list.append(round(metrics.mean_squared_error(response_test, response_pred), 4))\n",
    "    RMSE_list.append(round(np.sqrt(metrics.mean_squared_error(response_test, response_pred)), 4))\n",
    "    # add Try statement for linear regression??\n",
    "    importance = regressor.feature_importances_  # coef_[0].round(4) \n",
    "    feature_importance_df[model_names[model]] = importance\n",
    "     \n",
    "result_dict = {'Model Name':model_names, 'MAE':MAE_list, 'MSE':MSE_list, 'RMSE':RMSE_list}\n",
    "\n",
    "# e) Report the estimated metrics in a table for each model.\n",
    "results_df = pd.DataFrame(result_dict)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Train and evaluate models again for `features_encoded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>40.7477</td>\n",
       "      <td>4941.9744</td>\n",
       "      <td>70.2992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>31.0221</td>\n",
       "      <td>2503.6209</td>\n",
       "      <td>50.0362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extreme Gradient Boosting</td>\n",
       "      <td>30.3013</td>\n",
       "      <td>2136.4376</td>\n",
       "      <td>46.2216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Categorical Gradient Boosting</td>\n",
       "      <td>27.5132</td>\n",
       "      <td>1817.0982</td>\n",
       "      <td>42.6274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Light Gradient Boosting Model</td>\n",
       "      <td>30.9236</td>\n",
       "      <td>2193.4702</td>\n",
       "      <td>46.8345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model Name      MAE        MSE     RMSE\n",
       "0                  Decision Tree  40.7477  4941.9744  70.2992\n",
       "1                  Random Forest  31.0221  2503.6209  50.0362\n",
       "2      Extreme Gradient Boosting  30.3013  2136.4376  46.2216\n",
       "3  Categorical Gradient Boosting  27.5132  1817.0982  42.6274\n",
       "4  Light Gradient Boosting Model  30.9236  2193.4702  46.8345"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repeat Steps 6 and 7 again for encoded featrues to compare results\n",
    "result_list_enc = train_test_split(features_encoded, response, test_size=0.20, random_state=9)\n",
    "features_train_enc, features_test_enc, response_train_enc, response_test_enc = result_list_enc\n",
    "\n",
    "\n",
    "feature_names_enc = features_encoded.columns.to_list()\n",
    "feature_importance_df_enc = pd.DataFrame(feature_names_enc, columns=['features_encoded'])\n",
    "MAE_list_enc = []\n",
    "MSE_list_enc = []\n",
    "RMSE_list_enc = []\n",
    "\n",
    "for model in range(len(models_list)):\n",
    "    regressor = models_list[model]\n",
    "    regressor.fit(features_train_enc, response_train_enc)\n",
    "    response_pred = regressor.predict(features_test_enc)\n",
    "    MAE_list_enc.append(round(metrics.mean_absolute_error(response_test_enc, response_pred), 4))\n",
    "    MSE_list_enc.append(round(metrics.mean_squared_error(response_test_enc, response_pred), 4))\n",
    "    RMSE_list_enc.append(round(np.sqrt(metrics.mean_squared_error(response_test_enc, response_pred)), 4))\n",
    "    # add Try statement for linear regression??\n",
    "    importance = regressor.feature_importances_  # coef_[0].round(4) \n",
    "    feature_importance_df_enc[model_names[model]] = importance\n",
    "     \n",
    "result_dict_enc = {'Model Name':model_names, 'MAE':MAE_list_enc, 'MSE':MSE_list_enc, 'RMSE':RMSE_list_enc}\n",
    "\n",
    "results_df_enc = pd.DataFrame(result_dict_enc)\n",
    "results_df_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>33.7463</td>\n",
       "      <td>3311.0196</td>\n",
       "      <td>57.5415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>24.5008</td>\n",
       "      <td>1602.8037</td>\n",
       "      <td>40.0350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extreme Gradient Boosting</td>\n",
       "      <td>24.5657</td>\n",
       "      <td>1553.8186</td>\n",
       "      <td>39.4185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Categorical Gradient Boosting</td>\n",
       "      <td>23.8733</td>\n",
       "      <td>1475.6945</td>\n",
       "      <td>38.4148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Light Gradient Boosting Model</td>\n",
       "      <td>25.9839</td>\n",
       "      <td>1694.5872</td>\n",
       "      <td>41.1654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model Name      MAE        MSE     RMSE\n",
       "0                  Decision Tree  33.7463  3311.0196  57.5415\n",
       "1                  Random Forest  24.5008  1602.8037  40.0350\n",
       "2      Extreme Gradient Boosting  24.5657  1553.8186  39.4185\n",
       "3  Categorical Gradient Boosting  23.8733  1475.6945  38.4148\n",
       "4  Light Gradient Boosting Model  25.9839  1694.5872  41.1654"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all categorical variables as dummies (above) does worse than just 'weathersit' (below)\n",
    "results_df_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding all categorical variables as dummy varaibles makes the models worse.  This is probably because most of these variables are ordinal (i.e. the value change has meaning).  \n",
    "\n",
    "However, the type of encoding used on the `weathersit` predictor doesn't seem to make a difference in the result of the models. In both cases the **Categorical Gradient Boosting** model had the best performance with RMSE = 38.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Report the feature importance results of the best model.  \n",
    "a) Create a dataframe that has two columns: one for the name of the feature and one for the associated score. Make sure to report overall feature importance of each feature. (i.e. not for each label). You can aggregate using mean of importance values reported for each label.  \n",
    "b) Report feature importance in a bar chart.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance for best model using label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>Categorical Gradient Boosting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>holiday</td>\n",
       "      <td>0.214700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>windspeed</td>\n",
       "      <td>0.320726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>day</td>\n",
       "      <td>0.753000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mnth</td>\n",
       "      <td>1.205889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weekday</td>\n",
       "      <td>1.321940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weathersit</td>\n",
       "      <td>1.520687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hum</td>\n",
       "      <td>1.786963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>season</td>\n",
       "      <td>2.982908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>temp</td>\n",
       "      <td>4.222965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>atemp</td>\n",
       "      <td>4.694175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yr</td>\n",
       "      <td>7.896143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>workingday</td>\n",
       "      <td>11.432336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hr</td>\n",
       "      <td>61.647569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      features  Categorical Gradient Boosting\n",
       "5      holiday                       0.214700\n",
       "12   windspeed                       0.320726\n",
       "3          day                       0.753000\n",
       "2         mnth                       1.205889\n",
       "6      weekday                       1.321940\n",
       "8   weathersit                       1.520687\n",
       "11         hum                       1.786963\n",
       "0       season                       2.982908\n",
       "9         temp                       4.222965\n",
       "10       atemp                       4.694175\n",
       "1           yr                       7.896143\n",
       "7   workingday                      11.432336\n",
       "4           hr                      61.647569"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = 'Categorical Gradient Boosting'\n",
    "\n",
    "# feature importance for best model using label encoding\n",
    "feature_importance_df.loc[:,[\"features\", best]].sort_values(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Feature importance for best model using Dummy encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categorical Gradient Boosting</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>holiday</th>\n",
       "      <td>0.127205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windspeed</th>\n",
       "      <td>0.298391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>0.556611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weathersit</th>\n",
       "      <td>0.995315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnth</th>\n",
       "      <td>1.026996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday</th>\n",
       "      <td>1.317294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <td>2.798520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hum</th>\n",
       "      <td>6.315932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>6.369040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atemp</th>\n",
       "      <td>7.694861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yr</th>\n",
       "      <td>7.883331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workingday</th>\n",
       "      <td>12.136291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hr</th>\n",
       "      <td>52.480212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Categorical Gradient Boosting\n",
       "features                                 \n",
       "holiday                          0.127205\n",
       "windspeed                        0.298391\n",
       "day                              0.556611\n",
       "weathersit                       0.995315\n",
       "mnth                             1.026996\n",
       "weekday                          1.317294\n",
       "season                           2.798520\n",
       "hum                              6.315932\n",
       "temp                             6.369040\n",
       "atemp                            7.694861\n",
       "yr                               7.883331\n",
       "workingday                      12.136291\n",
       "hr                              52.480212"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature importance for best model using dummy encoding\n",
    "\n",
    "# extract just the original feature names\n",
    "feature_split = feature_importance_df_enc[['features_encoded']].applymap(lambda x: x.split(\"_\")[0])\n",
    "feature_importance_df_enc.insert(1, \"features\", feature_split)\n",
    "\n",
    "# aggregate importance by original feature by summing over dummy variables\n",
    "feature_importance_df_enc.groupby(\"features\").sum()[[best]].sort_values(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both **label encoded** and **dummy encoded** models ranked features in the same order of importance and relative magnitudes. For simplicity I will only plot importance for Label encoded set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.figure(figsize=(10, 6))\n",
    "# plot feature importance\n",
    "pyplot.bar(x = list(range(len(feature_importance_df))), \n",
    "           height = feature_importance_df['Categorical Gradient Boosting'], \n",
    "           tick_label = feature_importance_df['features'])\n",
    "pyplot.title('Feature Importance', size=20)\n",
    "pyplot.xlabel('Features')\n",
    "pyplot.ylabel('Importance Score')\n",
    "pyplot.xticks(rotation=90)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Drop 3 or more of the least importance features and re-train the best model.\n",
    "\n",
    "The features `holiday`,`windspeed`, and `day` were the three least important featrues. I will drop them and re-evaluate the model by repeating the steps (b)-(e) in Question-7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Categorical Gradient Boosting</td>\n",
       "      <td>23.5424</td>\n",
       "      <td>1463.6305</td>\n",
       "      <td>38.2574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost_New</td>\n",
       "      <td>24.6260</td>\n",
       "      <td>1579.8731</td>\n",
       "      <td>39.7476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model Name      MAE        MSE     RMSE\n",
       "3  Categorical Gradient Boosting  23.5424  1463.6305  38.2574\n",
       "5                   CatBoost_New  24.6260  1579.8731  39.7476"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst = ['holiday','windspeed','day']\n",
    "\n",
    "features_train_new = features_train.drop(worst, axis=1)\n",
    "features_test_new = features_test.drop(worst, axis=1)\n",
    "\n",
    "# b) Train the models using train part of the data.\n",
    "regressor = CatBoostRegressor(silent=True)\n",
    "regressor.fit(features_train_new, response_train)\n",
    "\n",
    "# c) Generate predictions over the test data.\n",
    "response_pred_new = regressor.predict(features_test_new)\n",
    "\n",
    "# d) Calculate the associated metrics (MAE, MSE and RMSE for regression problem) \n",
    "MAE = round(metrics.mean_absolute_error(response_test, response_pred_new), 4)\n",
    "MSE = round(metrics.mean_squared_error(response_test, response_pred_new), 4)\n",
    "RMSE = round(np.sqrt(metrics.mean_squared_error(response_test, response_pred_new)), 4)\n",
    "\n",
    "# e) Report the estimated metrics in a table for each model.\n",
    "results_dict_new = {'Mean Absolute Error':round(metrics.mean_absolute_error(response_test, response_pred_new), 4),\n",
    "    'Mean Squared Error':round(metrics.mean_squared_error(response_test, response_pred_new), 4),\n",
    "    'Root Mean Squared Error':round(np.sqrt(metrics.mean_squared_error(response_test, response_pred_new)), 4)}\n",
    "    \n",
    "result_dict = {'Model Name':'CatBoost_New', 'MAE':MAE, 'MSE':MSE, 'RMSE':RMSE}\n",
    "\n",
    "results_df_new = results_df.append(result_dict, ignore_index=True)\n",
    "\n",
    "results_df_new.iloc[[3,5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The re-trained model with the three least important features dropped actually does **worse** than the model with them included!  \n",
    "  \n",
    "I will now compare the feature importance for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features_new</th>\n",
       "      <th>CatBoost_New</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>season</td>\n",
       "      <td>2.839717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yr</td>\n",
       "      <td>8.010184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mnth</td>\n",
       "      <td>1.206623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hr</td>\n",
       "      <td>61.617183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weekday</td>\n",
       "      <td>1.701427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>workingday</td>\n",
       "      <td>11.524027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weathersit</td>\n",
       "      <td>1.542449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>temp</td>\n",
       "      <td>5.845002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>atemp</td>\n",
       "      <td>3.830482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hum</td>\n",
       "      <td>1.882906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  features_new  CatBoost_New\n",
       "0       season      2.839717\n",
       "1           yr      8.010184\n",
       "2         mnth      1.206623\n",
       "3           hr     61.617183\n",
       "4      weekday      1.701427\n",
       "5   workingday     11.524027\n",
       "6   weathersit      1.542449\n",
       "7         temp      5.845002\n",
       "8        atemp      3.830482\n",
       "9          hum      1.882906"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = regressor.feature_importances_  \n",
    "\n",
    "#create a dataframe for the feature importance of the new model\n",
    "feature_names_new = features_train_new.columns.to_list()\n",
    "feature_importance_df_new = pd.DataFrame(feature_names_new, columns=['features_new'])\n",
    "\n",
    "feature_importance_df_new['CatBoost_New'] = importance\n",
    "feature_importance_df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>Categorical Gradient Boosting</th>\n",
       "      <th>CatBoost_New</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>holiday</td>\n",
       "      <td>0.214700</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>windspeed</td>\n",
       "      <td>0.320726</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>day</td>\n",
       "      <td>0.753000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mnth</td>\n",
       "      <td>1.205889</td>\n",
       "      <td>1.206623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weekday</td>\n",
       "      <td>1.321940</td>\n",
       "      <td>1.701427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weathersit</td>\n",
       "      <td>1.520687</td>\n",
       "      <td>1.542449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hum</td>\n",
       "      <td>1.786963</td>\n",
       "      <td>1.882906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>season</td>\n",
       "      <td>2.982908</td>\n",
       "      <td>2.839717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>temp</td>\n",
       "      <td>4.222965</td>\n",
       "      <td>5.845002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>atemp</td>\n",
       "      <td>4.694175</td>\n",
       "      <td>3.830482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yr</td>\n",
       "      <td>7.896143</td>\n",
       "      <td>8.010184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>workingday</td>\n",
       "      <td>11.432336</td>\n",
       "      <td>11.524027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hr</td>\n",
       "      <td>61.647569</td>\n",
       "      <td>61.617183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      features  Categorical Gradient Boosting  CatBoost_New\n",
       "5      holiday                       0.214700           NaN\n",
       "12   windspeed                       0.320726           NaN\n",
       "3          day                       0.753000           NaN\n",
       "2         mnth                       1.205889      1.206623\n",
       "6      weekday                       1.321940      1.701427\n",
       "8   weathersit                       1.520687      1.542449\n",
       "11         hum                       1.786963      1.882906\n",
       "0       season                       2.982908      2.839717\n",
       "9         temp                       4.222965      5.845002\n",
       "10       atemp                       4.694175      3.830482\n",
       "1           yr                       7.896143      8.010184\n",
       "7   workingday                      11.432336     11.524027\n",
       "4           hr                      61.647569     61.617183"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join the two feature importance dataframes together\n",
    "feature_importance_df = feature_importance_df.join(feature_importance_df_new.set_index('features_new'), on='features')\n",
    "\n",
    "\n",
    "best_compare = ['features','Categorical Gradient Boosting', 'CatBoost_New']\n",
    "\n",
    "# compare feature importance for befor and after droping of predictors\n",
    "feature_importance_df[best_compare].sort_values(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Perform hyperparameter tuning with grid search for your best model.  \n",
    "\n",
    "My best model was `CatBoostRegressor()` but I could not get the `grid_search()` function to work for this model. Therefore, I chose `RandomForestRegressor()` to perform the hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(RandomForestRegressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warning! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below ran for 45 minutes before I interrupted the kernel! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "def grid_search(X, y, kfolds):\n",
    "    \n",
    "    #create a dictionary of all values we want to test\n",
    "    param_grid = {'n_estimators':[10,100,500], 'criterion':['mse','mae'], 'max_depth': np.arange(3, 15)}\n",
    "    # decision tree model\n",
    "    dtree_model=RandomForestRegressor()\n",
    "    #use gridsearch to test all values\n",
    "    dtree_gscv = GridSearchCV(dtree_model, param_grid, cv=kfolds)\n",
    "    #fit model to data\n",
    "    dtree_gscv.fit(X, y)\n",
    "    return dtree_gscv.best_params_\n",
    "\n",
    "# grid_search(X = features_train, y = response_train, kfolds = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell above ran for 45 minutes before I interrupted the kernel to kill the process, and went searching for more help. I found and followed the steps outlined on this [Medium article](https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74).\n",
    "\n",
    "#### Default Random Forest parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'criterion': 'mse',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 42,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search with Cross Validation\n",
    "I will use the Random Search with Cross Validation to narrow the options for grid search later.  It will randomly select different combinations of parameters from the 4320 possible.\n",
    "\n",
    "$2 * 12 * 2 * 3 * 3 * 10 = 4320$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 33.4min finished\n"
     ]
    }
   ],
   "source": [
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid,\n",
    "                              n_iter = 100, scoring='neg_mean_absolute_error', \n",
    "                              cv = 3, verbose=2, random_state=42, n_jobs=-1,\n",
    "                              return_train_score=True)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(features_train, response_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 800,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 100,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the best parameters from fitting the random search\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Random Search with MAE, MSE, and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=100, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=800, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) Train the models using train part of the data.\n",
    "random_best = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "                      max_depth=100, max_features='auto', max_leaf_nodes=None,\n",
    "                      max_samples=None, min_impurity_decrease=0.0,\n",
    "                      min_impurity_split=None, min_samples_leaf=1,\n",
    "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                      n_estimators=800, n_jobs=None, oob_score=False,\n",
    "                      random_state=42, verbose=0, warm_start=False)\n",
    "random_best.fit(features_train, response_train)\n",
    "\n",
    "# c) Generate predictions over the test data.\n",
    "response_pred = random_best.predict(features_test)\n",
    "\n",
    "# d) Calculate the associated metrics (MAE, MSE and RMSE for regression problem) \n",
    "MAE = round(metrics.mean_absolute_error(response_test, response_pred), 4)\n",
    "MSE = round(metrics.mean_squared_error(response_test, response_pred), 4)\n",
    "RMSE = round(np.sqrt(metrics.mean_squared_error(response_test, response_pred)), 4)\n",
    "\n",
    "# e) Report the estimated metrics in a table for each model.\n",
    "results_dict_new = {'Mean Absolute Error':round(metrics.mean_absolute_error(response_test, response_pred_new), 4),\n",
    "    'Mean Squared Error':round(metrics.mean_squared_error(response_test, response_pred_new), 4),\n",
    "    'Root Mean Squared Error':round(np.sqrt(metrics.mean_squared_error(response_test, response_pred_new)), 4)}\n",
    "    \n",
    "result_dict = {'Model Name':'RandomForests_RandomizedSearchCV', 'MAE':MAE, 'MSE':MSE, 'RMSE':RMSE}\n",
    "\n",
    "results_df_randomsearch = results_df_new.append(result_dict, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>24.5488</td>\n",
       "      <td>1618.7409</td>\n",
       "      <td>40.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForests_RandomizedSearchCV</td>\n",
       "      <td>24.4351</td>\n",
       "      <td>1602.0538</td>\n",
       "      <td>40.0257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model Name      MAE        MSE     RMSE\n",
       "1                     Random Forest  24.5488  1618.7409  40.2336\n",
       "6  RandomForests_RandomizedSearchCV  24.4351  1602.0538  40.0257"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare results with base Random Forest\n",
    "results_df_randomsearch.iloc[[1,6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Grid Search\n",
    "Now I use Grid search to explicitly test for the best combination of parameters identified by the random search.  Random search reduced the number of different combinations I need to try so it sould run much faster.\n",
    "\n",
    "$1 * 3 * 2 * 2 * 1 * 4 = 38$ combinations of settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(RandomForestRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [90, 100, 110],\n",
    "    'max_features': [2, 3],         # probably not the best choice for my data set\n",
    "    'min_samples_leaf': [1,2],\n",
    "    'min_samples_split': [2],\n",
    "    'n_estimators': [100, 500, 800, 1000]\n",
    "}\n",
    "\n",
    "# Best model for Random Search\n",
    "# {'n_estimators': 800,\n",
    "#  'min_samples_split': 2,   # default\n",
    "#  'min_samples_leaf': 1,    # default\n",
    "#  'max_features': 'auto',   # default\n",
    "#  'max_depth': 100,\n",
    "#  'bootstrap': True}        # default\n",
    "\n",
    "\n",
    "# Create a base model\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   47.8s\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed:  5.0min finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(features_train, response_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 90,\n",
       " 'max_features': 3,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 1000}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=90, max_features=3, max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) Train the models using train part of the data.\n",
    "final_model = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "                      max_depth=90, max_features='auto', max_leaf_nodes=None,\n",
    "                      max_samples=None, min_impurity_decrease=0.0,\n",
    "                      min_impurity_split=None, min_samples_leaf=1,\n",
    "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                      n_estimators=1000, n_jobs=None, oob_score=False,\n",
    "                      random_state=42, verbose=0, warm_start=False)\n",
    "regressor.fit(features_train, response_train)\n",
    "\n",
    "# c) Generate predictions over the test data.\n",
    "response_pred = regressor.predict(features_test)\n",
    "\n",
    "# d) Calculate the associated metrics (MAE, MSE and RMSE for regression problem) \n",
    "MAE = round(metrics.mean_absolute_error(response_test, response_pred), 4)\n",
    "MSE = round(metrics.mean_squared_error(response_test, response_pred), 4)\n",
    "RMSE = round(np.sqrt(metrics.mean_squared_error(response_test, response_pred)), 4)\n",
    "\n",
    "# e) Report the estimated metrics in a table for each model.\n",
    "results_dict_new = {'Mean Absolute Error':round(metrics.mean_absolute_error(response_test, response_pred_new), 4),\n",
    "    'Mean Squared Error':round(metrics.mean_squared_error(response_test, response_pred_new), 4),\n",
    "    'Root Mean Squared Error':round(np.sqrt(metrics.mean_squared_error(response_test, response_pred_new)), 4)}\n",
    "    \n",
    "result_dict = {'Model Name':'RandomForests_GridSearch', 'MAE':MAE, 'MSE':MSE, 'RMSE':RMSE}\n",
    "\n",
    "results_df_gridsearch = results_df_randomsearch.append(result_dict, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>24.5488</td>\n",
       "      <td>1618.7409</td>\n",
       "      <td>40.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForests_RandomizedSearchCV</td>\n",
       "      <td>24.4351</td>\n",
       "      <td>1602.0538</td>\n",
       "      <td>40.0257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForests_GridSearch</td>\n",
       "      <td>24.4275</td>\n",
       "      <td>1600.6322</td>\n",
       "      <td>40.0079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model Name      MAE        MSE     RMSE\n",
       "1                     Random Forest  24.5488  1618.7409  40.2336\n",
       "6  RandomForests_RandomizedSearchCV  24.4351  1602.0538  40.0257\n",
       "7          RandomForests_GridSearch  24.4275  1600.6322  40.0079"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare metrics for all the perammeter tuning models\n",
    "results_df_gridsearch.iloc[[1,6,7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random search and grid search were able to imporve the base Random Forest model very slightly, but in this case at least, the default parameters seem to be tuned well enough."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
