{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <h1>Assignment 7</h1> </center>\n",
    "<center> <h1>EIN 4933/6935 Python for Data Science Summer 2020</h1> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will evaluate a number of models using a data set from this <a href=\"http://archive.ics.uci.edu/ml/datasets.php\">web-site</a>.\n",
    "\n",
    "The data set that you choose must satisfy the following conditions:<br/>\n",
    "**Attribute Characteristics** (i.e. features data type): Categorical and Numerical (i.e. Integer and/or Real)<br/>\n",
    "**Associated Tasks** (i.e. prediction problem): Classification or Regression<br/>\n",
    "**Number of Attributes** (i.e. features): >=10<br/>\n",
    "**Number of Instances** (# of rows): >= 1000<br/>\n",
    "**Missing Values?:** Yes <br/>\n",
    "\n",
    "For example, <a href=\"http://archive.ics.uci.edu/ml/datasets/Adult\">Adults Data Set</a> satifies the given conditions. In most cases, the data values and the set of features/response variable names are stored in different data sources. For Adults Data Set, the data values and features/response variables are located in *adult.data* and *adult.names*, respectively. You can download each files by clicking Data Folder in the given <a href=\"http://archive.ics.uci.edu/ml/datasets/Adult\">link</a>.\n",
    "\n",
    "Use the data set that you choose to answer the questions below. You can create as many cells as you desire for all solutions.<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "1) Choose and download a data set from the <a href=\"http://archive.ics.uci.edu/ml/datasets.php\">link</a>. Make sure the set satisfies the above given conditions. Please note you will have to download both **.data** and **.names** files given in Data Folder web-page.<br/> \n",
    "2) Change the data values file from .data to .csv extension. This will be the csv file that you will use. This includes both data values and features/response variable names (i.e. header). For example, you can open .names file with a text editor (manually) and copy the features/response names. Or you can choose to read those names with a code.   \n",
    "3) Read the data into a dataframe from csv file that you prepare in Question 2.<br/>\n",
    "4) Remove any irrelevant data columns from the dataframe. If there are any missing values in the dataset, they should be replaced through a data imputation method. Any missing rows should be deleted from the dataset. Each column data type must be converted into an appropriate data type. The data types can be obtained either in .names info file.<br/>\n",
    "5) Perform the following preprocessing (Feature Extraction) tasks:\n",
    "a) Normalize the **numerical features** by using `MinMaxScaler` built-in function in scikit-learn package.\n",
    "b) Use a One-Hot Encoder method to encode **categorical features**. You can use `get_dummies()` from Pandas Package or `DictVectorizer()` from Scikit-Learn Package or any other built-in function that you are familiar with.<br/>\n",
    "6) Create two dataframes: response and features. Split these dataframes into train and test parts.<br/>\n",
    "7) You will evaluate a number of models.<br/> \n",
    "a) Choose at least 3 different models from the following list:<br/>\n",
    "Multiple Linear Regression, Decision Trees, Random Forest, Logistic Regression, Extreme Gradient Boosting, Categorical Gradient Boosting, Light Gradient Boosting Model, Support Vector Machines, Naïve Bayes, Nearest Neighbor or any other model that you are familiary with. All these models have built-in function available in scikit-learn package. We have covered many of them in the lectures. Make sure to use the correct model function (classifier or regressor) for your prediction problem.<br/>\n",
    "In your model evaluation, make sure to follow the following steps:<br/>\n",
    "b) Train the models using train part of the data.<br/>\n",
    "c) Generate predictions over the test data.<br/>\n",
    "d) Calculate the associated metrics (accuracy for classification problem and MAE, MSE and RMSE for regression problem) over test data by calling a built-in function from scikit learn package. <br/>\n",
    "e) Report the estimated metrics in a table for each model. <br/>\n",
    "8) Report the feature importance results of the best model.<br/> \n",
    "a) Create a dataframe that has two columns: one for the name of the feature and one for the associated score. Make sure to report overall feature importance of each feature. (i.e. not for each label). You can aggregate using mean of importance values reported for each label. <br/>\n",
    "b) Report feature importance in a bar chart. <br/>\n",
    "9) Drop at least 3 least importance features. Re-train your best model and evaluate your model by repeating the steps (b)-(e) in Question-7.<br/> \n",
    "10) Perform hyperparameter tuning with grid search for your best model. For example, the following code allows you to tune the hyperparameters of a decision tree model. The function returns the tuned parameters. You can use the same function by adjusting it for your best model. The candiate hyperparameters to be tuned can be obtained by calling `help` funciton in Python. For this specific example, you can call `help(DecisionTreeClassifier)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Choose and download a data set \n",
    "* from the <a href=\"http://archive.ics.uci.edu/ml/datasets.php\">link</a>.  \n",
    "* Make sure the set satisfies the above given conditions.  \n",
    "* Please note you will have to download both **.data** and **.names** files given in Data Folder web-page.\n",
    "\n",
    "#### I chose the `Mushrooms` dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Change the data values file from .data to .csv extension. \n",
    "This will be the csv file that you will use. This includes both data values and features/response variable names (i.e. header). For example, you can open `.names` file with a text editor (manually) and copy the features/response names. Or you can choose to read those names with code.   \n",
    "\n",
    "## 3) Read the data into a dataframe \n",
    "from csv file that you prepared in Question 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>edibility</th>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cap_shape</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>b</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>x</td>\n",
       "      <td>b</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>b</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cap_surface</th>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cap_color</th>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>g</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bruises</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>odor</th>\n",
       "      <td>p</td>\n",
       "      <td>a</td>\n",
       "      <td>l</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>l</td>\n",
       "      <td>p</td>\n",
       "      <td>a</td>\n",
       "      <td>l</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gill_attachment</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gill_spacing</th>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>w</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>w</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gill_size</th>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gill_color</th>\n",
       "      <td>k</td>\n",
       "      <td>k</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "      <td>n</td>\n",
       "      <td>p</td>\n",
       "      <td>g</td>\n",
       "      <td>g</td>\n",
       "      <td>n</td>\n",
       "      <td>w</td>\n",
       "      <td>k</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stalk_shape</th>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stalk_root</th>\n",
       "      <td>e</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>e</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stalk_surface_above</th>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stalk_surface_below</th>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stalk_color_above</th>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stalk_color_below</th>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>veil_type</th>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>veil_color</th>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ring_number</th>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ring_type</th>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spore_print</th>\n",
       "      <td>k</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>k</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>k</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>s</td>\n",
       "      <td>a</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>s</td>\n",
       "      <td>v</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>v</td>\n",
       "      <td>a</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>habitat</th>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>m</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>g</td>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>g</td>\n",
       "      <td>m</td>\n",
       "      <td>g</td>\n",
       "      <td>m</td>\n",
       "      <td>g</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\n",
       "edibility            p  e  e  p  e  e  e  e  p  e  e  e  e  p  e  e\n",
       "cap_shape            x  x  b  x  x  x  b  b  x  b  x  x  b  x  x  s\n",
       "cap_surface          s  s  s  y  s  y  s  y  y  s  y  y  s  y  f  f\n",
       "cap_color            n  y  w  w  g  y  w  w  w  y  y  y  y  w  n  g\n",
       "bruises              t  t  t  t  f  t  t  t  t  t  t  t  t  t  f  f\n",
       "odor                 p  a  l  p  n  a  a  l  p  a  l  a  a  p  n  n\n",
       "gill_attachment      f  f  f  f  f  f  f  f  f  f  f  f  f  f  f  f\n",
       "gill_spacing         c  c  c  c  w  c  c  c  c  c  c  c  c  c  w  c\n",
       "gill_size            n  b  b  n  b  b  b  b  n  b  b  b  b  n  b  n\n",
       "gill_color           k  k  n  n  k  n  g  n  p  g  g  n  w  k  n  k\n",
       "stalk_shape          e  e  e  e  t  e  e  e  e  e  e  e  e  e  t  e\n",
       "stalk_root           e  c  c  e  e  c  c  c  e  c  c  c  c  e  e  e\n",
       "stalk_surface_above  s  s  s  s  s  s  s  s  s  s  s  s  s  s  s  s\n",
       "stalk_surface_below  s  s  s  s  s  s  s  s  s  s  s  s  s  s  f  s\n",
       "stalk_color_above    w  w  w  w  w  w  w  w  w  w  w  w  w  w  w  w\n",
       "stalk_color_below    w  w  w  w  w  w  w  w  w  w  w  w  w  w  w  w\n",
       "veil_type            p  p  p  p  p  p  p  p  p  p  p  p  p  p  p  p\n",
       "veil_color           w  w  w  w  w  w  w  w  w  w  w  w  w  w  w  w\n",
       "ring_number          o  o  o  o  o  o  o  o  o  o  o  o  o  o  o  o\n",
       "ring_type            p  p  p  p  e  p  p  p  p  p  p  p  p  p  e  p\n",
       "spore_print          k  n  n  k  n  k  k  n  k  k  n  k  n  n  k  n\n",
       "population           s  n  n  s  a  n  n  s  v  s  n  s  s  v  a  y\n",
       "habitat              u  g  m  u  g  g  m  m  g  m  g  m  g  u  g  u"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# long string of header names\n",
    "n = \"cap_shape,cap_surface,cap_color,bruises,odor,gill_attachment,gill_spacing,gill_size,gill_color,stalk_shape,stalk_root,stalk_surface_above,stalk_surface_below,stalk_color_above,stalk_color_below,veil_type,veil_color,ring_number,ring_type,spore_print,population,habitat\"\n",
    "\n",
    "# split the above string at the comma to make a list of header names then add \"edibility\" at the beginning\n",
    "header_names = n.split(\",\")\n",
    "header_names.insert(0,\"edibility\")\n",
    "# print(len(header_names))\n",
    "# header_names\n",
    "\n",
    "# data = pd.read_csv(\"agaricus-lepiota.csv\", header=None, names=header_names)\n",
    "\n",
    "# Reading the data directly from the website\n",
    "data_url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\"\n",
    "data = pd.read_csv(data_url, header=None, names=header_names, na_values=\"?\")\n",
    "\n",
    "data.head(16).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Remove any irrelevant data columns from the dataframe. \n",
    "If there are any missing values in the dataset, they should be replaced through a data imputation method. Any missing rows should be deleted from the dataset. Each column data type must be converted into an appropriate data type. The data types can be obtained either in `.names` file or `info()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will keep all attributes for now.\n",
    "None of the attributes seem irrelevant so I will keep them all for now.  \n",
    "#### There are 2480 missing values, all in the `stalk_root` collumn.  \n",
    "That is, about a quarter of the values for that collumn are missing. I will try to impute them, but I may have to remove the column to avoid introducing too much bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "edibility              False\n",
       "cap_shape              False\n",
       "cap_surface            False\n",
       "cap_color              False\n",
       "bruises                False\n",
       "odor                   False\n",
       "gill_attachment        False\n",
       "gill_spacing           False\n",
       "gill_size              False\n",
       "gill_color             False\n",
       "stalk_shape            False\n",
       "stalk_root              True\n",
       "stalk_surface_above    False\n",
       "stalk_surface_below    False\n",
       "stalk_color_above      False\n",
       "stalk_color_below      False\n",
       "veil_type              False\n",
       "veil_color             False\n",
       "ring_number            False\n",
       "ring_type              False\n",
       "spore_print            False\n",
       "population             False\n",
       "habitat                False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b    3776\n",
       "e    1120\n",
       "c     556\n",
       "r     192\n",
       "Name: stalk_root, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the frequency of each value for the \"stalk_root\" column \n",
    "data.stalk_root.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will impute missing data in the `stalk_root` predictor based on the most common value (i.e. mode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new clean df to work with\n",
    "df_clean = data.copy()\n",
    "\n",
    "# impute missing values with the mode\n",
    "df_clean['stalk_root'].fillna(df_clean.stalk_root.mode().astype(\"str\")[0], inplace=True)\n",
    "\n",
    "df_clean['stalk_root'].isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8124 entries, 0 to 8123\n",
      "Data columns (total 23 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   edibility            8124 non-null   object\n",
      " 1   cap_shape            8124 non-null   object\n",
      " 2   cap_surface          8124 non-null   object\n",
      " 3   cap_color            8124 non-null   object\n",
      " 4   bruises              8124 non-null   object\n",
      " 5   odor                 8124 non-null   object\n",
      " 6   gill_attachment      8124 non-null   object\n",
      " 7   gill_spacing         8124 non-null   object\n",
      " 8   gill_size            8124 non-null   object\n",
      " 9   gill_color           8124 non-null   object\n",
      " 10  stalk_shape          8124 non-null   object\n",
      " 11  stalk_root           8124 non-null   object\n",
      " 12  stalk_surface_above  8124 non-null   object\n",
      " 13  stalk_surface_below  8124 non-null   object\n",
      " 14  stalk_color_above    8124 non-null   object\n",
      " 15  stalk_color_below    8124 non-null   object\n",
      " 16  veil_type            8124 non-null   object\n",
      " 17  veil_color           8124 non-null   object\n",
      " 18  ring_number          8124 non-null   object\n",
      " 19  ring_type            8124 non-null   object\n",
      " 20  spore_print          8124 non-null   object\n",
      " 21  population           8124 non-null   object\n",
      " 22  habitat              8124 non-null   object\n",
      "dtypes: object(23)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Perform the following preprocessing (Feature Extraction) tasks:\n",
    "* Normalize the **numerical features** by using `MinMaxScaler` built-in function in scikit-learn package.\n",
    "* Use a One-Hot Encoder method to encode **categorical features**. You can use `get_dummies()` from Pandas Package or `DictVectorizer()` from Scikit-Learn Package or any other built-in function that you are familiar with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I have 22 categorical features and 0 numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df_clean_cap = df_clean.iloc[:,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edibility</th>\n",
       "      <th>cap_shape</th>\n",
       "      <th>cap_surface</th>\n",
       "      <th>cap_color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8119</th>\n",
       "      <td>0</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8120</th>\n",
       "      <td>0</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8121</th>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8122</th>\n",
       "      <td>1</td>\n",
       "      <td>k</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8123</th>\n",
       "      <td>0</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8124 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      edibility cap_shape cap_surface cap_color\n",
       "0             1         x           s         n\n",
       "1             0         x           s         y\n",
       "2             0         b           s         w\n",
       "3             1         x           y         w\n",
       "4             0         x           s         g\n",
       "...         ...       ...         ...       ...\n",
       "8119          0         k           s         n\n",
       "8120          0         x           s         n\n",
       "8121          0         f           s         n\n",
       "8122          1         k           y         n\n",
       "8123          0         x           s         n\n",
       "\n",
       "[8124 rows x 4 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_cap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nvanb\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "\n",
    "df_clean_cap['edibility'] = labelencoder.fit_transform(df_clean_cap['edibility'])\n",
    "# response = df_clean_cap['edibility']\n",
    "\n",
    "features = df_clean_cap.drop('edibility', axis=1)\n",
    "features_encoded = pd.get_dummies(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap_shape_b</th>\n",
       "      <th>cap_shape_c</th>\n",
       "      <th>cap_shape_f</th>\n",
       "      <th>cap_shape_k</th>\n",
       "      <th>cap_shape_s</th>\n",
       "      <th>cap_shape_x</th>\n",
       "      <th>cap_surface_f</th>\n",
       "      <th>cap_surface_g</th>\n",
       "      <th>cap_surface_s</th>\n",
       "      <th>cap_surface_y</th>\n",
       "      <th>cap_color_b</th>\n",
       "      <th>cap_color_c</th>\n",
       "      <th>cap_color_e</th>\n",
       "      <th>cap_color_g</th>\n",
       "      <th>cap_color_n</th>\n",
       "      <th>cap_color_p</th>\n",
       "      <th>cap_color_r</th>\n",
       "      <th>cap_color_u</th>\n",
       "      <th>cap_color_w</th>\n",
       "      <th>cap_color_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8119</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8120</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8121</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8122</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8123</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8124 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cap_shape_b  cap_shape_c  cap_shape_f  cap_shape_k  cap_shape_s  \\\n",
       "0               0            0            0            0            0   \n",
       "1               0            0            0            0            0   \n",
       "2               1            0            0            0            0   \n",
       "3               0            0            0            0            0   \n",
       "4               0            0            0            0            0   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "8119            0            0            0            1            0   \n",
       "8120            0            0            0            0            0   \n",
       "8121            0            0            1            0            0   \n",
       "8122            0            0            0            1            0   \n",
       "8123            0            0            0            0            0   \n",
       "\n",
       "      cap_shape_x  cap_surface_f  cap_surface_g  cap_surface_s  cap_surface_y  \\\n",
       "0               1              0              0              1              0   \n",
       "1               1              0              0              1              0   \n",
       "2               0              0              0              1              0   \n",
       "3               1              0              0              0              1   \n",
       "4               1              0              0              1              0   \n",
       "...           ...            ...            ...            ...            ...   \n",
       "8119            0              0              0              1              0   \n",
       "8120            1              0              0              1              0   \n",
       "8121            0              0              0              1              0   \n",
       "8122            0              0              0              0              1   \n",
       "8123            1              0              0              1              0   \n",
       "\n",
       "      cap_color_b  cap_color_c  cap_color_e  cap_color_g  cap_color_n  \\\n",
       "0               0            0            0            0            1   \n",
       "1               0            0            0            0            0   \n",
       "2               0            0            0            0            0   \n",
       "3               0            0            0            0            0   \n",
       "4               0            0            0            1            0   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "8119            0            0            0            0            1   \n",
       "8120            0            0            0            0            1   \n",
       "8121            0            0            0            0            1   \n",
       "8122            0            0            0            0            1   \n",
       "8123            0            0            0            0            1   \n",
       "\n",
       "      cap_color_p  cap_color_r  cap_color_u  cap_color_w  cap_color_y  \n",
       "0               0            0            0            0            0  \n",
       "1               0            0            0            0            1  \n",
       "2               0            0            0            1            0  \n",
       "3               0            0            0            1            0  \n",
       "4               0            0            0            0            0  \n",
       "...           ...          ...          ...          ...          ...  \n",
       "8119            0            0            0            0            0  \n",
       "8120            0            0            0            0            0  \n",
       "8121            0            0            0            0            0  \n",
       "8122            0            0            0            0            0  \n",
       "8123            0            0            0            0            0  \n",
       "\n",
       "[8124 rows x 20 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Create response and features dataframes. \n",
    "Split these dataframes into **train** and **test** parts.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "result_list = train_test_split(features_encoded, response, test_size=0.20, random_state=9)\n",
    "features_train, features_test, response_train, response_test = result_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2831    0\n",
       "6228    1\n",
       "3533    1\n",
       "7255    0\n",
       "3777    0\n",
       "       ..\n",
       "8118    1\n",
       "501     0\n",
       "6782    1\n",
       "4444    0\n",
       "382     0\n",
       "Name: edibility, Length: 6499, dtype: int32"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) You will evaluate a number of models.   \n",
    "a) Choose at least 3 different models from the following list:  \n",
    "Multiple Linear Regression, Decision Trees, Random Forest, Logistic Regression, Extreme Gradient Boosting, Categorical Gradient Boosting, Light Gradient Boosting Model, Support Vector Machines, Naïve Bayes, Nearest Neighbor or any other model that you are familiary with. All these models have built-in function available in scikit-learn package. We have covered many of them in the lectures. Make sure to use the correct model function (classifier or regressor) for your prediction problem.  \n",
    "\n",
    "In your model evaluation, make sure to follow the following steps:  \n",
    "b) Train the models using train part of the data.  \n",
    "c) Generate predictions over the test data.  \n",
    "d) Calculate the associated metrics (accuracy for classification problem and MAE, MSE and RMSE for regression problem) over test data by calling a built-in function from scikit learn package.   \n",
    "e) Report the estimated metrics in a table for each model.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [RandomForestClassifier(), \n",
    "               DecisionTreeClassifier(), \n",
    "               XGBClassifier(), \n",
    "               CatBoostClassifier(silent=True),\n",
    "               LGBMClassifier()] # we put model functions in a list\n",
    "\n",
    "# model names in a list\n",
    "model_names = ['Random Forest', \n",
    "               'Decision Tree', \n",
    "               'Extreme Gradient Boosting', \n",
    "               'Categorical Gradient Boosting',\n",
    "               'Light Gradient Boosting'] \n",
    "\n",
    "\n",
    "feature_names = features_encoded.columns.to_list()\n",
    "feature_importance_df = pd.DataFrame(feature_names, columns=['features'])\n",
    "accuracy_list = []\n",
    "\n",
    "for model in range(len(models_list)):\n",
    "    classifier = models_list[model]\n",
    "    classifier.fit(features_train, response_train)\n",
    "    response_pred = classifier.predict(features_test)\n",
    "    accuracy_list.append(accuracy_score(response_pred, response_test))\n",
    "    importance = classifier.feature_importances_\n",
    "    feature_importance_df[model_names[model]] = importance\n",
    "     \n",
    "result_dict = {'Model Name':model_names, 'Accuracy':accuracy_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.717538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extreme Gradient Boosting</td>\n",
       "      <td>0.717538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Categorical Gradient Boosting</td>\n",
       "      <td>0.718154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Light Gradient Boosting</td>\n",
       "      <td>0.717538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model Name  Accuracy\n",
       "0                  Random Forest  0.720000\n",
       "1                  Decision Tree  0.717538\n",
       "2      Extreme Gradient Boosting  0.717538\n",
       "3  Categorical Gradient Boosting  0.718154\n",
       "4        Light Gradient Boosting  0.717538"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(result_dict)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Report the feature importance results of the best model.  \n",
    "a) Create a dataframe that has two columns: one for the name of the feature and one for the associated score. Make sure to report overall feature importance of each feature. (i.e. not for each label). You can aggregate using mean of importance values reported for each label.  \n",
    "b) Report feature importance in a bar chart.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Extreme Gradient Boosting</th>\n",
       "      <th>Categorical Gradient Boosting</th>\n",
       "      <th>Light Gradient Boosting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cap_shape_b</td>\n",
       "      <td>0.087371</td>\n",
       "      <td>0.130175</td>\n",
       "      <td>0.090338</td>\n",
       "      <td>6.305178</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cap_shape_c</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037553</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cap_shape_f</td>\n",
       "      <td>0.030203</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>1.988173</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cap_shape_k</td>\n",
       "      <td>0.074048</td>\n",
       "      <td>0.061152</td>\n",
       "      <td>0.037136</td>\n",
       "      <td>5.031148</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cap_shape_s</td>\n",
       "      <td>0.004283</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.036931</td>\n",
       "      <td>0.471697</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cap_shape_x</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>0.012643</td>\n",
       "      <td>0.011432</td>\n",
       "      <td>1.312018</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cap_surface_f</td>\n",
       "      <td>0.134853</td>\n",
       "      <td>0.109316</td>\n",
       "      <td>0.061204</td>\n",
       "      <td>26.643297</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cap_surface_g</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054709</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cap_surface_s</td>\n",
       "      <td>0.080128</td>\n",
       "      <td>0.039562</td>\n",
       "      <td>0.054913</td>\n",
       "      <td>7.970314</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cap_surface_y</td>\n",
       "      <td>0.045773</td>\n",
       "      <td>0.084647</td>\n",
       "      <td>0.005825</td>\n",
       "      <td>4.999963</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cap_color_b</td>\n",
       "      <td>0.030078</td>\n",
       "      <td>0.030579</td>\n",
       "      <td>0.043448</td>\n",
       "      <td>1.303170</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cap_color_c</td>\n",
       "      <td>0.007975</td>\n",
       "      <td>0.005223</td>\n",
       "      <td>0.004637</td>\n",
       "      <td>0.261310</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cap_color_e</td>\n",
       "      <td>0.092084</td>\n",
       "      <td>0.039567</td>\n",
       "      <td>0.054153</td>\n",
       "      <td>13.637753</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cap_color_g</td>\n",
       "      <td>0.056488</td>\n",
       "      <td>0.087513</td>\n",
       "      <td>0.134893</td>\n",
       "      <td>3.126765</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cap_color_n</td>\n",
       "      <td>0.077315</td>\n",
       "      <td>0.051116</td>\n",
       "      <td>0.049360</td>\n",
       "      <td>7.166907</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cap_color_p</td>\n",
       "      <td>0.037343</td>\n",
       "      <td>0.061361</td>\n",
       "      <td>0.060780</td>\n",
       "      <td>2.186833</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cap_color_r</td>\n",
       "      <td>0.005804</td>\n",
       "      <td>0.006204</td>\n",
       "      <td>0.063812</td>\n",
       "      <td>0.341027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cap_color_u</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.004694</td>\n",
       "      <td>0.051806</td>\n",
       "      <td>0.227519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cap_color_w</td>\n",
       "      <td>0.043824</td>\n",
       "      <td>0.017944</td>\n",
       "      <td>0.013306</td>\n",
       "      <td>3.224665</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cap_color_y</td>\n",
       "      <td>0.158711</td>\n",
       "      <td>0.249654</td>\n",
       "      <td>0.221749</td>\n",
       "      <td>13.710000</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         features  Random Forest  Decision Tree  Extreme Gradient Boosting  \\\n",
       "0     cap_shape_b       0.087371       0.130175                   0.090338   \n",
       "1     cap_shape_c       0.001008       0.000271                   0.000000   \n",
       "2     cap_shape_f       0.030203       0.002032                   0.004277   \n",
       "3     cap_shape_k       0.074048       0.061152                   0.037136   \n",
       "4     cap_shape_s       0.004283       0.004601                   0.036931   \n",
       "5     cap_shape_x       0.027273       0.012643                   0.011432   \n",
       "6   cap_surface_f       0.134853       0.109316                   0.061204   \n",
       "7   cap_surface_g       0.001633       0.001746                   0.000000   \n",
       "8   cap_surface_s       0.080128       0.039562                   0.054913   \n",
       "9   cap_surface_y       0.045773       0.084647                   0.005825   \n",
       "10    cap_color_b       0.030078       0.030579                   0.043448   \n",
       "11    cap_color_c       0.007975       0.005223                   0.004637   \n",
       "12    cap_color_e       0.092084       0.039567                   0.054153   \n",
       "13    cap_color_g       0.056488       0.087513                   0.134893   \n",
       "14    cap_color_n       0.077315       0.051116                   0.049360   \n",
       "15    cap_color_p       0.037343       0.061361                   0.060780   \n",
       "16    cap_color_r       0.005804       0.006204                   0.063812   \n",
       "17    cap_color_u       0.003805       0.004694                   0.051806   \n",
       "18    cap_color_w       0.043824       0.017944                   0.013306   \n",
       "19    cap_color_y       0.158711       0.249654                   0.221749   \n",
       "\n",
       "    Categorical Gradient Boosting  Light Gradient Boosting  \n",
       "0                        6.305178                      145  \n",
       "1                        0.037553                        0  \n",
       "2                        1.988173                      170  \n",
       "3                        5.031148                      160  \n",
       "4                        0.471697                       79  \n",
       "5                        1.312018                      173  \n",
       "6                       26.643297                      175  \n",
       "7                        0.054709                        0  \n",
       "8                        7.970314                      329  \n",
       "9                        4.999963                      176  \n",
       "10                       1.303170                      128  \n",
       "11                       0.261310                       40  \n",
       "12                      13.637753                      232  \n",
       "13                       3.126765                      242  \n",
       "14                       7.166907                      313  \n",
       "15                       2.186833                      152  \n",
       "16                       0.341027                        0  \n",
       "17                       0.227519                        0  \n",
       "18                       3.224665                      240  \n",
       "19                      13.710000                      246  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJUAAAKaCAYAAACHsmgxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdf7Dld13f8debXUKiUgzNtghJ2CgBjdUBWaCtFmn5YTQloQ4ZgtUGi0YdIlpqx606xEY7jT+wasWRKGkRWpAflq6T0BhQ0ZZSd0F+BYkucTVLrASC8iMhIcm7f9yz9XB7d+/5bPa759ybx2PmTs7317nv772zmc0z3+/3VHcHAAAAAEY8aNkDAAAAALD1iEoAAAAADBOVAAAAABgmKgEAAAAwTFQCAAAAYJioBAAAAMAwUQkAAACAYaISALAyqupQVd1ZVZ+e+3rk/XzPp1XV4RM144Lf8z9V1Y+fzO95NFX1o1X1mmXPAQBsP6ISALBqnt3dXzT3desyh6mqncv8/vfHVp4dAFh9ohIAsCVU1d+tqndU1V9W1Xur6mlz2769qv6wqj5VVTdX1XfN1n9hkrckeeT8lU/rryRafzXT7IqpH6yq9yX5TFXtnB33pqq6rar+pKpevODcu6uqZzPeUlWfqKrvrqonVdX7ZufzC3P7v6Cq/mdV/Yeq+quq+lBVPX1u+yOral9V3V5VB6vqO+e2/WhVvbGqXlNVn0zy3Ul+KMnzZuf+3mP9vOZ/FlX1L6vqo1X151X17XPbT6uql1XVn87m+x9VddpmvyMAYPvxf68AgJVXVY9Kcm2Sb0vy35M8PcmbqurLu/u2JB9N8o+T3JzkqUneUlX7u/vdVfWNSV7T3WfOvd8i3/b5SS5I8rEk9yX5jST/bbb+zCRvraqbuvv6BU/jKUnOnc23b3Yez0jy4CR/UFVv6O63z+37xiRnJPnmJL9eVed09+1JXpvkxiSPTPLlSW6oqpu7+22zYy9KcnGSf5bkIbP3eEx3f+vcLEf9ec22PyLJw5I8Kskzk7yxqt7c3Z9I8tNJvjLJ30/yf2az3rfA7wgA2GZcqQQArJo3z650+cuqevNs3bcmua67r+vu+7r7hiQHknxTknT3td394V7z9iS/meQf3M85fr67b+nuO5M8Kcmu7r6yu+/u7puT/HKSSwbe78e6+7Pd/ZtJPpPktd390e7+SJLfS/KEuX0/muRnu/tz3f1rSW5KckFVnZXk65L84Oy93pPkV7IWco74X9395tnP6c6NBlng5/W5JFfOvv91ST6d5HFV9aAk/zzJ93X3R7r73u5+R3fflU1+RwDA9uNKJQBg1Tynu9+6bt2jk1xcVc+eW/fgJL+dJLOrka5I8tis/U+zL0jy/vs5xy3rvv8jq+ov59btyFoMWtRfzL2+c4PlL5pb/kh399zyn2btyqRHJrm9uz+1btueo8y9oQV+Xh/v7nvmlu+YzXdGklOTfHiDtz3m7wgA2H5EJQBgK7glyau7+zvXb6iqhyR5U9Zu9/pv3f252RVOR+5x6/XHZO1KoS+YW37EBvvMH3dLkj/p7nOPZ/jj8KiqqrmwdHbWbpm7NcnDq+qhc2Hp7CQfmTt2/fl+3vICP69j+ViSzyb5siTvXbftqL8jAGB7cvsbALAVvCbJs6vqG6pqR1WdOnug9JlJTsnas4NuS3LP7CqcZ80d+xdJ/mZVPWxu3XuSfFNVPbyqHpHk+zf5/r+f5JOzh3efNpvh71TVk07YGX6+v5XkxVX14Kq6OMlXZO3WsluSvCPJv5v9DL46yQuT/OdjvNdfJNk9u3Ut2fzndVTdfV+Sa5L8zOyB4Tuq6u/NQtWxfkcAwDYkKgEAK28WUy7K2ieZ3Za1q2L+VZIHza7YeXGS1yf5RJJvydpVPUeO/VDWHm598+w5TY9M8uqsXWlzKGvPE/q1Tb7/vUmeneTxSf4ka1fs/ErWHmY9hf+dtYd6fyzJv03y3O7++Gzb85PsztpVS/81yRWz5xcdzRtm//x4Vb17s5/XAn4ga7fK7U9ye5KfyNrv4ai/o4H3BgC2kPr82/UBAFimqnpBku/o7q9b9iwAAMfi/xwBAAAAMExUAgAAAGCY298AAAAAGOZKJQAAAACGiUoAAAAADNu57AFOlDPOOKN379697DEAAAAAto13vetdH+vuXRtt2zZRaffu3Tlw4MCyxwAAAADYNqrqT4+2ze1vAAAAAAwTlQAAAAAYJioBAAAAMExUAgAAAGCYqAQAAADAMFEJAAAAgGGiEgAAAADDRCUAAAAAholKAAAAAAwTlQAAAAAYJioBAAAAMExUAgAAAGCYqAQAAADAMFEJAAAAgGGiEgAAAADDRCUAAAAAholKAAAAAAwTlQAAAAAYJioBAAAAMGzSqFRV51fVTVV1sKr2brD9JVX1wap6X1W9raoePbft3qp6z+xr35RzAgAAADBm51RvXFU7krw8yTOTHE6yv6r2dfcH53b7gyR7uvuOqvqeJD+Z5HmzbXd29+Onmg8AAACA4zfllUpPTnKwu2/u7ruTvC7JRfM7dPdvd/cds8V3JjlzwnkAAAAAOEGmjEqPSnLL3PLh2bqjeWGSt8wtn1pVB6rqnVX1nCkGBAAAAOD4THb7W5LaYF1vuGPVtybZk+Tr51af3d23VtWXJvmtqnp/d3943XGXJbksSc4+++wTMzUAAAAAm5oyKh1Octbc8plJbl2/U1U9I8kPJ/n67r7ryPruvnX2z5ur6neSPCHJ50Wl7r46ydVJsmfPng2DFQAAALC97N577bJH2NShqy5Y9giTm/L2t/1Jzq2qc6rqlCSXJPm8T3GrqickeUWSC7v7o3PrT6+qh8xen5Hka5PMP+AbAAAAgCWa7Eql7r6nqi5Pcn2SHUmu6e4bq+rKJAe6e1+Sn0ryRUneUFVJ8mfdfWGSr0jyiqq6L2vh66p1nxoHAAAAwBJNeftbuvu6JNetW/fSudfPOMpx70jyVVPOBgAAAMDxm/L2NwAAAAC2KVEJAAAAgGGiEgAAAADDRCUAAAAAholKAAAAAAwTlQAAAAAYJioBAAAAMExUAgAAAGCYqAQAAADAMFEJAAAAgGGiEgAAAADDRCUAAAAAholKAAAAAAwTlQAAAAAYJioBAAAAMExUAgAAAGCYqAQAAADAMFEJAAAAgGGiEgAAAADDRCUAAAAAholKAAAAAAwTlQAAAAAYJioBAAAAMExUAgAAAGCYqAQAAADAMFEJAAAAgGGiEgAAAADDRCUAAAAAholKAAAAAAwTlQAAAAAYJioBAAAAMExUAgAAAGCYqAQAAADAMFEJAAAAgGGiEgAAAADDRCUAAAAAholKAAAAAAwTlQAAAAAYJioBAAAAMExUAgAAAGCYqAQAAADAMFEJAAAAgGGiEgAAAADDRCUAAAAAholKAAAAAAwTlQAAAAAYJioBAAAAMExUAgAAAGCYqAQAAADAMFEJAAAAgGGiEgAAAADDRCUAAAAAholKAAAAAAwTlQAAAAAYJioBAAAAMExUAgAAAGCYqAQAAADAMFEJAAAAgGGiEgAAAADDRCUAAAAAholKAAAAAAwTlQAAAAAYJioBAAAAMExUAgAAAGCYqAQAAADAMFEJAAAAgGGiEgAAAADDRCUAAAAAholKAAAAAAwTlQAAAAAYJioBAAAAMExUAgAAAGCYqAQAAADAMFEJAAAAgGGiEgAAAADDRCUAAAAAholKAAAAAAwTlQAAAAAYJioBAAAAMExUAgAAAGCYqAQAAADAMFEJAAAAgGGiEgAAAADDRCUAAAAAholKAAAAAAwTlQAAAAAYJioBAAAAMExUAgAAAGCYqAQAAADAMFEJAAAAgGGiEgAAAADDRCUAAAAAholKAAAAAAwTlQAAAAAYJioBAAAAMGzSqFRV51fVTVV1sKr2brD9JVX1wap6X1W9raoePbft0qr649nXpVPOCQAAAMCYyaJSVe1I8vIk35jkvCTPr6rz1u32B0n2dPdXJ3ljkp+cHfvwJFckeUqSJye5oqpOn2pWAAAAAMZMeaXSk5Mc7O6bu/vuJK9LctH8Dt392919x2zxnUnOnL3+hiQ3dPft3f2JJDckOX/CWQEAAAAYMGVUelSSW+aWD8/WHc0Lk7zlOI8FAAAA4CTaOeF71wbresMdq741yZ4kXz9ybFVdluSyJDn77LOPb0oAAAAAhk15pdLhJGfNLZ+Z5Nb1O1XVM5L8cJILu/uukWO7++ru3tPde3bt2nXCBgcAAADg2KaMSvuTnFtV51TVKUkuSbJvfoeqekKSV2QtKH10btP1SZ5VVafPHtD9rNk6AAAAAFbAZLe/dfc9VXV51mLQjiTXdPeNVXVlkgPdvS/JTyX5oiRvqKok+bPuvrC7b6+qH8tamEqSK7v79qlmBQAAAGDMlM9USndfl+S6deteOvf6Gcc49pok10w3HQAAAADHa8rb3wAAAADYpkQlAAAAAIaJSgAAAAAME5UAAAAAGCYqAQAAADBMVAIAAABgmKgEAAAAwDBRCQAAAIBhohIAAAAAw0QlAAAAAIaJSgAAAAAME5UAAAAAGCYqAQAAADBMVAIAAABgmKgEAAAAwDBRCQAAAIBhohIAAAAAw0QlAAAAAIaJSgAAAAAME5UAAAAAGCYqAQAAADBMVAIAAABgmKgEAAAAwDBRCQAAAIBhohIAAAAAw0QlAAAAAIaJSgAAAAAME5UAAAAAGCYqAQAAADBMVAIAAABgmKgEAAAAwDBRCQAAAIBhohIAAAAAw0QlAAAAAIaJSgAAAAAME5UAAAAAGCYqAQAAADBMVAIAAABgmKgEAAAAwDBRCQAAAIBhohIAAAAAw0QlAAAAAIaJSgAAAAAME5UAAAAAGCYqAQAAADBMVAIAAABgmKgEAAAAwDBRCQAAAIBhohIAAAAAw0QlAAAAAIaJSgAAAAAME5UAAAAAGCYqAQAAADBMVAIAAABgmKgEAAAAwDBRCQAAAIBhohIAAAAAw0QlAAAAAIaJSgAAAAAME5UAAAAAGCYqAQAAADBMVAIAAABgmKgEAAAAwDBRCQAAAIBhohIAAAAAw0QlAAAAAIaJSgAAAAAME5UAAAAAGCYqAQAAADBMVAIAAABgmKgEAAAAwDBRCQAAAIBhohIAAAAAw0QlAAAAAIaJSgAAAAAME5UAAAAAGCYqAQAAADBMVAIAAABgmKgEAAAAwDBRCQAAAIBhohIAAAAAw0QlAAAAAIaJSgAAAAAME5UAAAAAGCYqAQAAADBMVAIAAABgmKgEAAAAwDBRCQAAAIBhohIAAAAAw0QlAAAAAIaJSgAAAAAME5UAAAAAGCYqAQAAADBMVAIAAABgmKgEAAAAwLCFolJVfV1Vffvs9a6qOmfB486vqpuq6mBV7d1g+1Or6t1VdU9VPXfdtnur6j2zr32LfD8AAAAATo6dm+1QVVck2ZPkcUn+Y5IHJ3lNkq/d5LgdSV6e5JlJDifZX1X7uvuDc7v9WZIXJPmBDd7izu5+/ALnAAAAAMBJtsiVSv8kyYVJPpMk3X1rkocucNyTkxzs7pu7++4kr0ty0fwO3X2ou9+X5L6hqQEAAABYqkWi0t3d3Uk6SarqCxd870cluWVu+fBs3aJOraoDVfXOqnrORjtU1WWzfQ7cdtttA28NAAAAwP2xSFR6fVW9IskXV9V3Jnlrkl9e4LjaYF0PzHZ2d+9J8i1Jfraqvuz/e7Puq7t7T3fv2bVr18BbAwAAAHB/bPpMpe7+6ap6ZpJPZu25Si/t7hsWeO/DSc6aWz4zya2LDja7zS7dfXNV/U6SJyT58KLHAwAAADCdY0al2cO2r+/uZyRZJCTN25/k3NknxX0kySVZu+poU1V1epI7uvuuqjojaw8F/8nB7w8AAADARI55+1t335vkjqp62Ogbd/c9SS5Pcn2SP0zy+u6+saqurKoLk6SqnlRVh5NcnOQVVXXj7PCvSHKgqt6b5LeTXLXuU+MAAAAAWKJNb39L8tkk76+qGzL7BLgk6e4Xb3Zgd1+X5Lp1614693p/1m6LW3/cO5J81QKzAQAAALAEi0Sla2dfAAAAAJBksQd1v6qqTkny2Nmqm7r7c9OOBQAAAMAq2zQqVdXTkrwqyaEkleSsqrq0u3932tEAAAAAWFWL3P72siTP6u6bkqSqHpvktUmeOOVgAAAAAKyuY37628yDjwSlJOnuP0ry4OlGAgAAAGDVLXKl0oGqemWSV8+W/2mSd003EgAAAACrbpGo9D1JXpTkxVl7ptLvJvnFKYcCAAAAYLUtEpV2Jvm57v6ZJKmqHUkeMulUAAAAAKy0RZ6p9LYkp80tn5bkrdOMAwAAAMBWsEhUOrW7P31kYfb6C6YbCQAAAIBVt0hU+kxVfc2Rhap6YpI7pxsJAAAAgFW3yDOVvj/JG6rq1tnylyR53nQjAQAAALDqNo1K3b2/qr48yeOy9ulvH+ruz00+GQAAAAAr66i3v1XVk6rqEUkyi0hfk+THk7ysqh5+kuYDAAAAYAUd65lKr0hyd5JU1VOTXJXkV5P8VZKrpx8NAAAAgFV1rNvfdnT37bPXz0tydXe/Kcmbquo9048GAAAAwKo61pVKO6rqSHR6epLfmtu2yAO+AQAAANimjhWHXpvk7VX1sSR3Jvm9JKmqx2TtFjgAAAAAHqCOGpW6+99W1duSfEmS3+zunm16UJLvPRnDAQAAALCajnkbW3e/c4N1fzTdOAAAAABsBcd6phIAAAAAbEhUAgAAAGDYQlGpqh5dVc+YvT6tqh467VgAAAAArLJNo1JVfWeSNyZ5xWzVmUnePOVQAAAAAKy2Ra5UelGSr03yySTp7j9O8remHAoAAACA1bZIVLqru+8+slBVO5P0dCMBAAAAsOoWiUpvr6ofSnJaVT0zyRuS/Ma0YwEAAACwyhaJSnuT3Jbk/Um+K8l1SX5kyqEAAAAAWG07F9jntCTXdPcvJ0lV7Zitu2PKwQAAAABYXYtcqfS2rEWkI05L8tZpxgEAAABgK1gkKp3a3Z8+sjB7/QXTjQQAAADAqlskKn2mqr7myEJVPTHJndONBAAAAMCqW+SZSt+f5A1Vdets+UuSPG+6kQAAAABYdZtGpe7eX1VfnuRxSSrJh7r7c5NPBgAAAMDKWuRKpSR5UpLds/2fUFXp7l+dbCoAAAAAVtqmUamqXp3ky5K8J8m9s9WdRFSayO691y57hE0duuqCZY8AAAAALNEiVyrtSXJed/fUwwAAAACwNSzy6W8fSPKIqQcBAAAAYOtY5EqlM5J8sKp+P8ldR1Z294WTTQUAAADASlskKv3o1EMAAAAAsLVsGpW6++0nYxAAAAAAto5Nn6lUVX+3qvZX1aer6u6qureqPnkyhgMAAABgNS3yoO5fSPL8JH+c5LQk3zFbBwAAAMAD1CLPVEp3H6yqHd19b5L/WFXvmHguAAAAAFbYIlHpjqo6Jcl7quonk/x5ki+cdiwAAAAAVtkit79922y/y5N8JslZSb55yqEAAAAAWG2LRKXndPdnu/uT3f1vuvslSf7x1IMBAAAAsLoWiUqXbrDuBSd4DgAAAAC2kKM+U6mqnp/kW5J8aVXtm9v00CQfn3owAAAAAFbXsR7U/Y6sPZT7jCQvm1v/qSTvm3IoAAAAAFbbUaNSd/9pVR1O8pnufvtJnAkAAACAFXfMZyp1971J7qiqh52keQAAAADYAo51+9sRn03y/qq6Iclnjqzs7hdPNhUAAAAAK22RqHTt7AsAAAAAkiwQlbr7VVV1SpLHzlbd1N2fm3YsAAAAAFbZplGpqp6W5FVJDiWpJGdV1aXd/bvTjgYAAADAqlrk9reXJXlWd9+UJFX12CSvTfLEKQcDAAAAYHUd89PfZh58JCglSXf/UZIHTzcSAAAAAKtukSuVDlTVK5O8erb8T5O8a7qRAAAAAFh1i0Sl70nyoiQvztozlX43yS9OORQAAAAAq22RT3+7q6p+IcnbktyXtU9/u3vyyQAAAABYWYt8+tsFSX4pyYezdqXSOVX1Xd39lqmHAwAAAGA1Lfrpb/+wuw8mSVV9WZJrk4hKAAAAAA9Qi3z620ePBKWZm5N8dKJ5AAAAANgCFrlS6caqui7J65N0kouT7K+qb06S7v71CecDAAAAYAUtEpVOTfIXSb5+tnxbkocneXbWIpOoBAAAAPAAs8inv337yRgEAAAAgK1jkU9/OyfJ9ybZPb9/d1843VgAAAAArLJFbn97c5JXJvmNJPdNOw4AAAAAW8EiUemz3f3zk08CAAAAwJaxSFT6uaq6IslvJrnryMrufvdkUwEAAACw0haJSl+V5NuS/KP89e1vPVsGAAAA4AFokaj0T5J8aXffPfUwAAAAAGwND1pgn/cm+eKpBwEAAABg61jkSqW/neRDVbU/n/9MpQsnmwoAAACAlbZIVLpi8ikAAAAA2FI2jUrd/faTMQgAAAAAW8dRo1JVfSprn/L2/21K0t39NyabCgAAAICVdtSo1N0PPZmDAAAAALB1LPJMJQA4Lrv3XrvsETZ16KoLlj0CAABsSQ9a9gAAAAAAbD2iEgAAAADDRCUAAAAAholKAAAAAAwTlQAAAAAYJioBAAAAMExUAgAAAGCYqAQAAADAMFEJAAAAgGGiEgAAAADDRCUAAAAAholKAAAAAAwTlQAAAAAYJioBAAAAMGzSqFRV51fVTVV1sKr2brD9qVX17qq6p6qeu27bpVX1x7OvS6ecEwAAAIAxk0WlqtqR5OVJvjHJeUmeX1Xnrdvtz5K8IMl/WXfsw5NckeQpSZ6c5IqqOn2qWQEAAAAYM+WVSk9OcrC7b+7uu5O8LslF8zt096Hufl+S+9Yd+w1Jbuju27v7E0luSHL+hLMCAAAAMGDKqPSoJLfMLR+erZv6WAAAAAAmNmVUqg3W9Yk8tqouq6oDVXXgtttuGxoOAAAAgOM3ZVQ6nOSsueUzk9x6Io/t7qu7e09379m1a9dxDwoAAADAmCmj0v4k51bVOVV1SpJLkuxb8Njrkzyrqk6fPaD7WbN1AAAAAKyAyaJSd9+T5PKsxaA/TPL67r6xqq6sqguTpKqeVFWHk1yc5BVVdePs2NuT/FjWwtT+JFfO1gEAAACwAnZO+ebdfV2S69ate+nc6/1Zu7Vto2OvSXLNlPMBAAAAcHymvP0NAAAAgG1KVAIAAABgmKgEAAAAwDBRCQAAAIBhohIAAAAAw0QlAAAAAIaJSgAAAAAME5UAAAAAGCYqAQAAADBMVAIAAABgmKgEAAAAwDBRCQAAAIBhohIAAAAAw0QlAAAAAIaJSgAAAAAME5UAAAAAGCYqAQAAADBMVAIAAABgmKgEAAAAwDBRCQAAAIBhohIAAAAAw3YuewAAAODk2L332mWPsKlDV12w7BEAWJArlQAAAAAYJioBAAAAMExUAgAAAGCYqAQAAADAMFEJAAAAgGE+/Q0A2LJ8khUAwPK4UgkAAACAYaISAAAAAMNEJQAAAACGiUoAAAAADBOVAAAAABgmKgEAAAAwTFQCAAAAYJioBAAAAMAwUQkAAACAYaISAAAAAMNEJQAAAACGiUoAAAAADBOVAAAAABgmKgEAAAAwTFQCAAAAYJioBAAAAMAwUQkAAACAYaISAAAAAMNEJQAAAACGiUoAAAAADBOVAAAAABgmKgEAAAAwTFQCAAAAYJioBAAAAMAwUQkAAACAYaISAAAAAMNEJQAAAACGiUoAAAAADBOVAAAAABgmKgEAAAAwTFQCAAAAYJioBAAAAMAwUQkAAACAYaISAAAAAMNEJQAAAACGiUoAAAAADBOVAAAAABgmKgEAAAAwTFQCAAAAYJioBAAAAMAwUQkAAACAYaISAAAAAMNEJQAAAACGiUoAAAAADBOVAAAAABgmKgEAAAAwTFQCAAAAYNjOZQ8AAADwQLd777XLHmFTh666YNkjACtGVIIHKH9xAQAA4P5w+xsAAAAAw0QlAAAAAIaJSgAAAAAME5UAAAAAGCYqAQAAADBMVAIAAABgmKgEAAAAwDBRCQAAAIBhohIAAAAAw0QlAAAAAIaJSgAAAAAME5UAAAAAGCYqAQAAADBMVAIAAABgmKgEAAAAwDBRCQAAAIBhohIAAAAAw0QlAAAAAIZNGpWq6vyquqmqDlbV3g22P6Sqfm22/X9X1e7Z+t1VdWdVvWf29UtTzgkAAADAmJ1TvXFV7Ujy8iTPTHI4yf6q2tfdH5zb7YVJPtHdj6mqS5L8RJLnzbZ9uLsfP9V8AADA1rZ777XLHmFTh666YNkjAExmyiuVnpzkYHff3N13J3ldkovW7XNRklfNXr8xydOrqiacCQAAAIATYMqo9Kgkt8wtH56t23Cf7r4nyV8l+ZuzbedU1R9U1dur6h9MOCcAAAAAgya7/S3JRlcc9YL7/HmSs7v741X1xCRvrqqv7O5Pft7BVZcluSxJzj777BMwMgAAAACLmPJKpcNJzppbPjPJrUfbp6p2JnlYktu7+67u/niSdPe7knw4yWPXf4Puvrq793T3nl27dk1wCgAAAABsZMqotD/JuVV1TlWdkuSSJPvW7bMvyaWz189N8lvd3VW1a/ag71TVlyY5N8nNE84KAAAAwIDJbn/r7nuq6vIk1yfZkeSa7r6xqq5McqC79yV5ZZJXV9XBJLdnLTwlyVOTXFlV9yS5N8l3d/ftU80KAAAAwJgpn6mU7r4uyXXr1r107vVnk1y8wXFvSvKmKWcDAAAA4PhNefsbAAAAANuUqAQAAADAMFEJAAAAgGGiEgAAAADDRCUAAAAAholKAAAAAAwTlQAAAAAYJioBAAAAMExUAgAAAGCYqAQAAADAMFEJAAAAgGGiEgAAAADDRCUAAAAAholKAAAAAAwTlQAAAAAYJioBAAAAMGznsgcAAE6u3XuvXfYImzp01QXLHgH+H39mAGBjrlQCAAAAYJioBAAAAMAwUQkAAACAYaISAAAAAMNEJQAAAACGiUoAAAAADBOVAAAAABgmKgEAAAAwTFQCAAAAYJioBAAAAMAwUQkAAACAYaISAAAAAMNEJQAAAACGiUoAAAAADBOVAAAAABgmKgEAAAAwTFQCALxLlagAACAASURBVAAAYJioBAAAAMCwncseAACANbv3XrvsETZ16KoLlj0CALAiXKkEAAAAwDBRCQAAAIBhohIAAAAAw0QlAAAAAIaJSgAAAAAME5UAAAAAGCYqAQAAADBMVAIAAABgmKgEAAAAwDBRCQAAAIBhohIAAAAAw0QlAAAAAIaJSgAAAAAME5UAAAAAGCYqAQAAADBMVAIAAABgmKgEAAAAwDBRCQAAAIBhohIAAAAAw0QlAAAAAIaJSgAAAAAME5UAAAAAGCYqAQAAADBMVAIAAABgmKgEAAAAwLCdyx4AAAAAmNbuvdcue4RNHbrqgmWPwCBXKgEAAAAwTFQCAAAAYJioBAAAAMAwUQkAAACAYaISAAAAAMNEJQAAAACGiUoAAAAADBOVAAAAABgmKgEAAAAwTFQCAAAAYNjOZQ8AwF/bvffaZY+wqUNXXbDsEQAAgBXgSiUAAAAAholKAAAAAAwTlQAAAAAYJioBAAAAMExUAgAAAGCYqAQAAADAMFEJAAAAgGGiEgAAAADDRCUAAAAAholKAAAAAAwTlQAAAAAYJioBAAAAMExUAgAAAGDYzmUPAAAAwPaxe++1yx5hU4euumDZI8C24EolAAAAAIa5UgkAgBPOlQoAsP2JSsCW5z9cAACYgr9nwrG5/Q0AAACAYaISAAAAAMNEJQAAAACGiUoAAAAADPOgbhjgQX0AAACwZtKoVFXnJ/m5JDuS/Ep3X7Vu+0OS/GqSJyb5eJLndfeh2bZ/neSFSe5N8uLuvn7KWQHgWERlAAD4fJPd/lZVO5K8PMk3JjkvyfOr6rx1u70wySe6+zFJ/n2Sn5gde16SS5J8ZZLzk/zi7P0AAAAAWAFTPlPpyUkOdvfN3X13ktcluWjdPhcledXs9RuTPL2qarb+dd19V3f/SZKDs/cDAAAAYAVUd0/zxlXPTXJ+d3/HbPnbkjyluy+f2+cDs30Oz5Y/nOQpSX40yTu7+zWz9a9M8pbufuO673FZkstmi49LctMkJ7M9nJHkY8se4gRxLqtpO51Lsr3Ox7mspu10Lsn2Oh/nspq207kk2+t8nMtq2k7nkmyv83Euq2k7ncuJ9uju3rXRhimfqVQbrFtfsI62zyLHpruvTnL1+GgPPFV1oLv3LHuOE8G5rKbtdC7J9jof57KattO5JNvrfJzLatpO55Jsr/NxLqtpO51Lsr3Ox7mspu10LifTlLe/HU5y1tzymUluPdo+VbUzycOS3L7gsQAAAAAsyZRRaX+Sc6vqnKo6JWsP3t63bp99SS6dvX5ukt/qtfvx9iW5pKoeUlXnJDk3ye9POCsAAAAAAya7/a2776mqy5Ncn2RHkmu6+8aqujLJge7el+SVSV5dVQezdoXSJbNjb6yq1yf5YJJ7kryou++datYHiO10m6BzWU3b6VyS7XU+zmU1badzSbbX+TiX1bSdziXZXufjXFbTdjqXZHudj3NZTdvpXE6ayR7UDQAAAMD2NeXtbwAAAABsU6ISAAAAAMNEJQAAAACGiUpwklTVq2f//L5lzwJbgT8zcP9U1d+oqocuew7g5Nvqf/6rakdV/Ytlz8HGqurUZc/A6hCVtrGqOrWqXlJVv15Vb6qqf7FV/wVQVa+qqi+eWz69qq5Z5kzH4YlV9egk/3w2/8Pnv5Y93PGoqidusO7Zy5jlRKiqi4/8BayqfmT2Z+drlj3X8aiq8zZY97QljHJ/bMc/My/Z4OuFVfX4Zc92PLbZn5nLq+r0Zc9xIlTVnqp6f5L3JflAVb13o39fbwVVdc78312q6rSq2r28ie6fqnpsVb2tqj4wW/7qqvqRZc/F9rFd/vzPPvn7omXPwVF9oKr+Z1VdVVXfVFUPW/ZAx6uqDlTVi7bL3wGWwae/bWNV9fokn0rymtmq5yc5vbsv/r/t3Xm0bVV15/HvDxuwbygrKcuGpoiWCoiIDVAq2FQUIgWCWrFB0FS0rNLEtnQkKLYRxRGDQ8sIWKKYssERkGEERfOkUekEZDhsotihVCEiEgsFya/+2PvA4fK4991z3n3rrN+dnzHeuO/scy9vTtZc554199r7tItqNpK+bnu3lY4tMkkvA14C7ABcDmjqadveoUlgc5B0IXCo7W+Mj/8z8Ge2H902stlIusT2LpL2Bt4OvAt4fY/5jAuWjwBHAduMXx9p+7FNA1uF0DnzMeCRwGfGQ/sB5wEPBj5p+6hWsc0ibM68BXg2cCFwPHCaO32TJOkS4KW2zxwf7w28z/YubSNbPUnnA3vavn58fEfgbNt7tI1sNpI2AK8GPjB5DyPpUtsPaxvZ6o2Ni6Vz5BrgfOAttq/a8lHNRtJewBuBBwK3Z/h90+vvmaT5/1bgHsDHgV9Pjtu+sFlQc5B0GbeeM/RYZwCSHgD8B2Av4GnAL213d5JM0r8DDgOexfD69SHg9F7fA7RQTaVgki62vetKx3og6WLgCbavHh/fG9hge+e2ka2epPfbfskyz99rkueik7QD8CngOcDewPOB/W1f0zSwGU0alZLeDnzD9sd6a15OSLoL8A5gd+BuwInAO2z/S9PAZhA2Z04DnmH7n8fHd2WYQwcCF9i+1Q6zRZY0ZwAkCXgKw5vLRwKfAI6z/b2mga2SpLNt77XSsR5IumjpIqXX9zIAks6zvcf0PNlYjj2QdBRwI/Cx8dCzx6+/Ava23c3OZUnfAv4cuIAhJwB6aoxNhM3/L23ksG3vu8WD2QwkbTv1cBvgEODeto9oFNLMJN2PoaH0eGBX4BfAWbbf3jSwOUjaCtgfeD/wLwwnmN5j+xdNA+vA7VsHUNbU1yU9xvZXASQ9Gji7cUyzOho4R9KnGDr8zwTe2jak2Sy3OB6dAXRx+Yjt70t6NvD3wI+Bp9i+rnFY87hc0geAJwHvkLQ1/V4mfANwHXAnhjcul/XYUIKsOQM8ALh+6vENwANtXyfpt41imkfSnMG2JV0BXAH8DrgX8ClJn7f9mrbRrWzq0sNzx3H5O4bfmc8C/rFVXHO6UtLTbZ8CIOkA4OeNY5rHzyXtyLhbQdLBwM/ahjSzvZY0Kr4xaV5Iem6zqGZzje1/aB3EZrLR+T95fehpl4/tfZZ7XtKhtj+8peKZ10aalH8t6Sygu6YS8COGndZvs/3i1sHMS9IuDCeUngacxHAydm/gi0B3Tf8trXYqBZrajnwH4EEMk94MW3q/2eMWa7jpHjH7MmxJPsP2N6ee62anwkp6OMu/kS3v/5phy/tvAXrcYg0g6c7AHzLsuPiupH8D7Gz79PH5bups3N13MvBmYFvgA8ANtg9uGtga6GHOTEj6S4ZdSSePh/4IOIWhcf63tp/TKrZZhM2ZlwGHMjQsjgX+3vYN45nL79resWmAm+A2zupPdHl2f2zAnAjcdzz0E+B5ve0emxh3+P4tsCdwNXAZ8BzbP2wa2AzG3zP/xfbXxsePAj5oe9eeXpcBJP0VcDvg04zvZaCvBsxE4uvAbZF0oe1eTipNN/5hOAHzSOAlPe68lLQrQ9PlcQwnzL7LcBXJcU0Dm4GkC4BfAscBJ9n+7dRzn7Z9ULPgOlFNpUAabmx7myZvXHp6s7+S3n6pLKeHXNZjjUEfYzMh6ZG2z19y7Hm2J5+oFjM2PY0L3HSD+70ZGuRnTY9T0rhAX2Mj6U0Ml7rdanEv6d8DV6SMTW9n9+GmS0Vl+9olx7vLBW66RHmrnvORtAfD5SF3HQ9dC7wQ+Cawn+1PtIpttdIus1pOTzW2kg6bl9N19juGpvLRtr/dKKS5jK/LezNcBvdchjmzXdOgZiBpB9vfX+b5mDmzVqqptI719GZ/Jb39UllO2LjE5AJVZ4uqcllcNWcWU+WyuHrMR8OnPsn2L5ccj1mIheXSXY3dlqRcoK860/AhClsD5wBnAV/uccflpkirs7XQ7X0Pymahlb+lG0nd0aRxScoFqs4WVeWyuGrOLKbKZXF1l4/ta5Y2lEYv3+LBrJ2kXLqrsWUk5QJ91dlTbe9s+09tf2RpQ0nSoa0CWwNpdbbZVVNpfUt6s98VSXtLOmz8+30kbT/19BMbhbUWqsYWV1djU3OmLICksalcFldSPkkLsaRcuqgxSVtJeuYK39brBxDdlm7qzPaVK3xLTw2ylXQxZ1qqplJJ0c2LsKQ3AK8FXjceugPw0cnz9bGVC62bOktSc6ZrNWcWU9K4JOUCWfkkLcSScumixsZPrP1vK3zPss93qOpsMSXlsiaqqbS+dTVBgnYqHAg8Hfg1gO2fAndrGtHa6arGIKrOVtLT2NScWWA1ZxZL0tn9pFwgL59N0MWc2URd5BJYY5+X9CpJ95d078mf1kGtoS7qbBN10SALnDNNVFMpXMqb/bCdCtd7uEO+4aZPgOlWSo1BXJ0ljU3NmQVVc2bxJJ3dT8oFsvJJWogl5ZJUY6PDgZcCXwYuGP+cv+xPLKikOttEXTTIAudME/Xpb8HGN/uPBB5k+w8k3Rf4pO29Goe2apIuAnYDLpx8kpCkS2zv0jay1ZP0KmAn4MnA2xl+YX7M9jFNA5tBUo1BXJ3FjE3NmcVVc2YxSfpL4Drg44w7/KC/Jh9k5QJZ+Uj6su3HtY5jcwjLJabG0qTUmaStgINtf2KZ73lvL82YmjPzq6ZSsLA3++faftTkIx3HnQpf6TEXAElPBp4yPjzd9udbxjOrpBqDrDoLHJvJnBFwWs2ZxVBzZjFJumwjh217hy0ezJyScoGsfJIWYmG5JNXYHYCXAJNGzD8CH7B9Q7Og5hBWZxENMsiaM63cvnUAZU1db9uSEi4Z+YSkDwD3lPQnDDsVPtg4pnl8A7gTw+U832gcyzySagyy6ixmbMZLkM6cNJIk3UnSdrZ/0DaymcSMy6jmzAKyvf3K39WHpFwgLp/Dx68vnTpmoMeFWEwuYTX2fobLqt83Pn7eeOxFzSKaT0ydMd7vioAGWdicaaJ2KgVLumQEonb3vAg4Avgiw66LxwNvsn1808BmkFZjEFVnMWMj6XxgT9vXj4/vCJxte4+2ka1e0rhMBO0iixmbpLP7SblAXj5l8STVmKSLbe+60rGy5SXt7kmaM61UUylcygIZQNLvA49i6OifZ/uKxiHNRNK3GRbIV42PtwXOsf2gtpHNJqnGIKfOIGdsJF1k++FLjnX7pjKlCQM37SL7me3fjI/vBPxep7vIYsZG0rEMZ/c/PB56HnCj7e7O7iflAln5JC3EwnJJqrELgUNsf298vAPwKduPaBvZbJLqLEnSnGmlmkrhUhbIYbt7zgCeumTXxWdtP6ltZLNJqTHIqjPIGRtJnweOsX3K+PgA4GW2u/g0rmmBTZikXWQxY5N0dj8pF8jKJ2khFpZLUo09EfgQ8H2G92UPBA6z/aWmgc0orM5iGmRJc6aVuqdSsI0skI+R1OsC+dXAbkt39wA95nI58DVJJzMs9g8AzpX0CgDb724Z3GqE1RgE1VnY2LwYOFHSexly+THw/LYhzeyTwJ5Tj28cj3XXhBndftJQArB9/dhY6lHS2NwoacclZ/dvbBzTrJJygax89liy6PqipIubRTOfpFxiasz2GZJ2Ah7E8Pv/W7Z/2ziseSTVWdL9rmLmTCvVVMoWs0AGfgJcO/X4WoaFZY++N/6ZOHn8ercGscwrqcYgq85ixmb8Jf8YSXdl2GF77Uo/s8CSmjAAV0p6+pJdZD9vHNOsksbm1cCXJN3i7H7bkGaWlAtk5ZO0EEvKpfsak3TQbTy1oyRsf3qLBrT5JNVZUoOs+znTWjWVsiUtkGN299g+snUMm1FSjUFQnRE2NpL2Ax4KbCMJANtvahrUbJKaMJC1iyxmbJLO7iflAnH5JC3EYnIJqbE/WuY5A702lWLqjKAGWcicaaruqRRM0gnAzgw7YW5aIAPfgb4WyJLesNzzPTVqJN0HeA3jAnly3Pa+zYKaUVKNQVydxYyNpP8J3BnYBzgWOBg41/YLmwY2A0k7AicC92WqCWP7n5oGNqeEXWQJY7PM2X2Ars7uJ+UCeflMSNqakIVY77mk1lia3utsIuF+VzVnNp9qKgVLWiAnkXQ68HHgVQxn+Q8FrrT92qaBzaBqbHEljY2kS2zvMvX1rsCnbT9lxR9eUAlNmInpXWSTY53uIgP6HhtJH1rmads+fIsFM6ekXCArn6SFWFguMTU2IekewBu4+WbQGxg+QOWadlGtXlKdTeu9QZY4Z1qpplLpQtjungts7z5ZII/HNth+fOvY1rukOksi6Vzbj5L0VeAg4CrgUts7NQ5tJklNmKRdZJA1NqWslaSFWFIuiSSdBFzKLT8tbVfbyzZpFk1SnaU2yMp86p5KwcIWyCcy7O7Zn6ndPU0jmt3kozZ/Ni5gfgrcr2E8MwurMQiqs7Cx+YykewLvBC5kuJzvg21Dms1tNWGaBjWfPad2kR0p6Wg6vddF0tiknN2HrFwgIx/bvd4D5laScplIqLEpO9p+xtTjIyVd1CyaGYXVWdz9rsLmTBNbtQ6grKkTgW8B2wNHAj8AzmsZ0By2tX0ccIPtDWNH/zGtg5rRW8YXr1cyXAJ3LPDnbUOaWVKNQVaddT82kg4Z//pR27+0fRLDNfsPtn1Ew9Dmsaft5wNXj5cgPha4f+OY5vGb8ev/k3Rfhqb59g3jmUfS2BzPcHP+Z45/fsVw74seJeUCQflIuoekd0s6f/xz9Pj+pjtJuRBUY8B1kvaePJC0F3Bdw3jmklBntg9b5k83O66WSJozTdROpWzb2j5O0sttbwA2SNrQOqgZxezusX3q+NdrGM6I9yypxiCozsgYm9cBnwROAh4BMF6v39U1+0ssbcJcRb9NGAjaRUbW2ESc3R8l5QJZ+RzPcGnSM8fHz2NYiHV1adIoKZekGnsJ8OGpxsvVwAvahTO3mDoL292TNGeaqKZStqQF8vTunmOAu9Pp7p7xsqQ/AbZjag522t1PqjEIqjMyxuYqSV8CdpB0ytInbT+9QUzzimjCSDrE9icZd5EBJ0k6Fdim0zeUEDI2o+sk7W37LOj+7H5SLpCVT9JCLCmXmBqzfRGwq6S7j49/1TikeSXVWUyDjKA500rdqDuYpP2BMxm2708WyEfavtXirGw5ks5hGJcLgBsnx8dLe7pSNba4EsZG0h0Zdih9BHjR0ufHHVhdmDRhJG1v+7Lx2NZ02oSRdKHtR0y+to5nHmljAyDp4Qw3tr3F2X3bF7eLajZJuUBWPpK+Arx6yULsXbYf2zay1QvLJanG3gYcNZ68QNK9gFfa/ou2kc0mrM4usv3wlY71IGnOtFJNpdKFpN09vb7grgdJdZZC0u2AD/Y+BklNGABJn2eYI7sBX176fE+7yNLGZlrQ2f2oXCAjn6SFWFIuEyE19nXbuy051u1rdVKdJTXIJhLmTCt1+VuwsAXyyQy7Lr7A1O6eTp0q6Wm2P9s6kHmF1RgE1VnK2Ni+UdIDW8exGaRdyrcfN+8iO7pxLPNKG5uos/tJuUBWPkmXJiXlklRjwO0kbT3eTxFJdwK2bhzTzJLqjKD7XYXNmSZqp1KwsMusut/dI+lahnt0CLgLw82Gbxgf2/bdG4Y3k6Qag4w6m0gaGw0fU78Tw027fz05brubj61NupRvImgXWeLYxJzdT8oFsvJJWoiF5ZJUY68Bns5wrx4DhwOn2D6qaWAzSqqziYQGWdKcaaV2KmW7s+3Xtg5iM+l+d4/tu7WOYQ0k1RgE1NmUpLG5N8Mnce07dcxAN00l29dLOg84s8cmxcak7CJLHBuyzu4n5QJZ+TzV9usnD2xfLelpQI8L5KRcYmrM9lGSLgGexHAS9s22T2sc1jxi6iysQRYzZ1qpplK27hfIS3b3vF5Swu6evYCLbP9a0nMZzpD/te0fNQ5tFt3XGGTWGSFjA2D7sNYxbA4pTZglLhovGet2FxlEjs1HgTMkTZ/d/3DbkGaWlAtk5ZO0EEvKJanGsP054HMbe07SVzq7h09SncU0yAibMy3U5W+BEi+zSjKecdkV2IXhcovjgINsP75pYKtQNba4Esdm6pf8LfR42VXCpXzTxrFZyjU27Un6Q24+u396z2f3k3KBnHySLk1KygVyamwlG7tsaZEl1dm4ntljSYPsfNsPbRvZbNbLnFkr1VQqXUja3aObP2noCOBy28fVdbuLIanOkkh6xtTDbYADgZ/aflmjkGaW1IRJs57GpsOz+7cpKRfoL5+khVhSLsvprcaW0+P755Q6S2qQrSRpzqyVaioFS1ogJ+zumZC0gWEb72HA44ArGcZp56aBzSCpxiCuzqLGZpqkrYAv2N53xW8uayppF9l60tvZ/eUk5QJZ+SQtxMJySaqx7ppKy+mtzlIaZCtJmjNrpe6plO39DB9buSvwGoYF8keA7hbIwO9sW9IBwHvG3T2Htg5qRs8C/hh4oe0rJD0AeGfjmGaVVGOQVWdpYzNtJ+ABrYOYRWAT5tSpv9+0i6xRLHMJHJvlJJ1RTMoFsvLZpnUAm1FSLkk1ptYBbGZd1VnY/a6WkzRn1kQ1lbIlLZCvlfQ64LnA4zR8lPUdGsc0E9tXAO+eevwj4ITJ485ehJNqDILqjKCxmbpP1MQVQK+fbBfThAGwfdL0Y0l/B3yhUTjzihqbUhZA0kIsKZeuSPp94FEMY3De+D564nltolozSXXWVYOszKeaStmSFshJu3tW0tOLcFKNQVadxYyN7bu1jmFzCWvCbEy3u8jWwdhMSzq7n5QL5OVTFk83NSbpRcARwBcZ4j5G0ptsHw9g+9KW8ZVlJTXIupkzrVRTKVvMAjlsd89KenoRjqkxiKuzmLG5jftDvcf2DxuHtjl024SBuF1kS/U+NjFn95Nygbx8lpG0EOsql6AaezWwm+2rACRtC5wDHN80qrXTVZ0lCZozTdSNutexzhbIy0q6gVrSTQeTagzi6qybsQm7gfrGmjCvW7pLpmx5SWOzkbP7jwduOrvfk6RcIDKf21yISXpYTztJUnJJqjFJZwBPtX39+PiOwGdtP6ltZLNLqbOV9PSeOWnOtFJNpXWsp8m+krBGTNK4xOQCVWetTP6/SzoCuHy8P1TMWPQsfBdZtyR9G9hz6dl92w9qG9nqJeUCWfkkLcTCckmqsROAnYGTGZowBwDnAt8BsP3u2/7pxZNUZ5DTIEuaM63U5W/rW3UUG1lHWyyrxhZXT2MTc3+owCbMxj5l8AQ6/JTBsLH5CXDt1ONrgR83imVeSblAVj5JlyYl5ZJUY98b/0ycPH7t9V6LMXUWdr+rpDnTRDWVSopurkEOexFeb7qpszAx94ciqAkzivmUQbLG5nLga5JucXZf0iugu7P7SblAVj5JC7GkXGJqzPaRrWPYzJLqLKZBRtCcaaWaSutbVwvkoN09SS/CK+mqxiCqzlbSzdiE3UA9qQkDQbvIyBqbpLP7SblAVj5JC7GkXGJqTNJ9GJr8D2Xq05Ft79ssqPkk1VlSgyxmzrRSTaVwKQvksN09SS/CMTUGcXUWNTYr2Gblb1kYSU0YyNpFFjM2SWf3k3KBuHySFmIxuYTV2InAx4H9gRcDhwJXNo1oPjF1RlCDLGzONFE36g6WdDO4pBuoJd10MKnGIK7OosZmOT3dtHts9P0xQ5PvzLEJ8wTbJ6zwo13qaRdZ0tgknd1PygXy8imLJ6nGJF1ge3dJl9jeZTy2ocdPf00j6Q3LPd9ToyZpzrRSO5WyJV1mlbS7J+ksRVKNQVadpY1NhLBL+TZFN7vIwsYm6ex+Ui4QlE/SQiwpF4JqDLhh/PozSfsBPwXu1zCeuSTVWU9No02QNGeaqKZStqQFcm2xXExJNQZBdUbe2Cynm/tDbYJumjCbKGk7dE9js+14T6iX294AbJC0oXVQM0rKBbLySVqIJeWSVGNvkXQP4JXAMcDdgT9rG9JcYuosqUFG1pxpoppK2ZIWyDG7e8JehJNqDILqjLCxWUf3h0pqwqTpaWySzu4n5QJZ+SQtxJJySaqxQ4Czxnta7iPp3sC7gM+0DWtmSXUW0yAja840UU2lbDEL5LDdPUkvwjE1BnF1FjM2aTdQX2eSdpH1JOnsflIukJVP0kIsKZekGtvF9i8nD2z/QtJuLQOaU1KdJTXIkuZME9VUCpa0QA7b3RPzIpxUY5BVZ2Fjs57uD9VdE2Yd7SLraWySzu4n5QJZ+SQtxJJySaqxrSTdy/bVAGMuPa9fk+osqUGWNGea6HlSlhUkLZDJ2t0T8yIcVmMQVGdhYxN1f6ikJkzaLrKgsUk6u5+UC2Tlk7QQS8olqcaOBs6R9CmG1+VnAm9tG9JckuosqUGWNGea2Kp1AGVNnQh8C9geOBL4AXBey4DmsK3t44AbbG+wfTjwmNZBzWj6RfhVwLH0+yKcVGOQVWdJYzO5P9Qbx4+w/SrwT5JeMblHVC/GJsy5wEHAwcBXJR0+eb63Jgw37yJ7ge1Dgd2B1zaOaSZhY7OVpHtNHnR+dj8pF8jK51YLMaDXhVhSLjE1ZvsE4BnA/2E4yXeQ7Y+0jWouSXV2CCDbl9reB3gycGDjmGYVM2daqf9Z2WIusyJodw9ZZymSagyy6ixpbGLuD0XepXxJu8iSxibp7H5SLpCVT9KlSUm5JNUYtr8JfLN1HJtJUp0l7e6JmjMt9FrEZdMkLZBri+ViSqoxyKqzmLEJuz9UUhMGsj5lMGZsbJ8g6XxgX4bLEg8aF2bdScoF4vJJWojF5BJWY2li6oygBlnNmfnJ7ukTcstqSNofOBO4PzcvkN9ou7sdMZI+DLx80oyZ7O4ZL0/qiqSLgScseRHeYHvntpGtXlKNQVydxYxN0v2hJJ0A7Myw2+qmJgzwHeiuCcN4OeJt6qkhmDY2pWwJkh7CzQuxM3peiCXlUhZXSp1Jej7wOuAWDbLOL08sM+qym1g2WdJlVkm7e5LOUiTVGGTVWdLYxNxAnaxL+bpqGm2CqLEpZUtIujQpKZeyuFLqHrBYzQAABKlJREFUrHb3lGnVVMqWtECuLZaLKanGIKjOyBqbmPtDhTVhonaRpY1NKaWUspZSGmRlfr0ulsqmSVogJ+3uSXoRTqoxyKqzpLGJuT9UUhNmFLOLLHBsSimllFLWXK8LjLJpYhbIYbt7ksTUGMTVWdLYJN1APaYJM4rZRUbe2JRSSimlrLm6UXe4lJvBlcVVNba4UsYm7AbqF9jeXdIltncZj22w/fjWsc1C0ldtP0bSacDfMOwi+5TtHRuHtmppY1NKKaWUsiXUTqVwQZdZlQVVNba4gsYm6f5QMZfyjZJ2kaWNTSmllFLKmqumUimllEWXdH+opCYMZH3KYNrYlFJKKaWsua1aB1BKKaWsYHJ/qDdLehNwDnBU45hmdQjDpeeX2t4HeDJwYOOY5nGrXWRAr7vI0samlFJKKWXN9Xqmt5RSyjoRdgP1pEv5IGsXWdrYlFJKKaWsuV7f+JVSSllHgu4PldSEgaxPGUwbm1JKKaWUNVdvlkoppZQtJ6kJk7aLLGpsSimllFK2BNluHUMppZSybkh6CDc3Yc7ouAkTp8amlFJKKWV1qqlUSimllFJKKaWUUlatPv2tlFJKKaWUUkoppaxaNZVKKaWUUkoppZRSyqpVU6mUUkopZQWSbpR00dSf7Wb4b9xT0n/d/NGVUkoppbRR91QqpZRSSlmBpH+2fdc5/xvbAafaftgqf+52tm+c598upZRSSlkLtVOplFJKKWUGkm4n6Z2SzpN0iaQ/HY/fVdIZki6U9A1JB4w/8lfAjuNOp3dKeoKkU6f+e++V9ILx7z+QdISks4BDJO0o6XOSLpB0pqQHj993iKRLJV0s6ctb9v9AKaWUUta727cOoJRSSimlA3eSdNH498tsHwi8ELjG9h6StgbOlnQ68GPgQNu/kvSvgK9KOgX4H8DDbD8cQNITVvg3f2N77/F7zwBebPu7kh4NvA/YFzgC+I+2L5d0z82bcimllFLK8qqpVEoppZSysusmzaApTwF2kXTw+PgewE7AT4C3SXoc8C/AvwV+b4Z/8+Mw7HwC9gQ+KWny3Nbj17OB/yXpE8CnZ/g3SimllFJmVk2lUkoppZTZCPjvtk+7xcHhErb7ALvbvkHSD4BtNvLzv+OWtyJY+j2/Hr9uBfxyI00tbL943Lm0H3CRpIfbvmqWZEoppZRSVqvuqVRKKaWUMpvTgJdIugOApD+QdBeGHUv/d2wo7QM8cPz+a4G7Tf38D4GHSNpa0j2AJ27sH7H9K+AySYeM/44k7Tr+fUfbX7N9BPBz4P6bP81SSimllI2rnUqllFJKKbM5FtgOuFDDdWlXAv8JOBH4jKTzgYuAbwHYvkrS2ZIuBf7B9qvHy9YuAb4LfH2Zf+s5wPsl/QVwB+B/AxcD75S0E8OuqTPGY6WUUkopW4Rst46hlFJKKaWUUkoppXSmLn8rpZRSSimllFJKKatWTaVSSimllFJKKaWUsmrVVCqllFJKKaWUUkopq1ZNpVJKKaWUUkoppZSyatVUKqWUUkoppZRSSimrVk2lUkoppZRSSimllLJq1VQqpZRSSimllFJKKatWTaVSSimllFJKKaWUsmr/H+TvAzCH+egrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.figure(figsize=(20, 10))\n",
    "# plot feature importance\n",
    "pyplot.bar(x = list(range(len(importance))), height = feature_importance_df['Decision Tree'], tick_label = feature_names)\n",
    "pyplot.title('Feature Importance')\n",
    "pyplot.xlabel('Features')\n",
    "pyplot.ylabel('Importance Score')\n",
    "pyplot.xticks(rotation=90)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Drop at least 3 least importance features and re-train your best model.\n",
    "Evaluate your model by repeating the steps (b)-(e) in Question-7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Perform hyperparameter tuning with grid search for your best model.  \n",
    "For example, the following code allows you to tune the hyperparameters of a decision tree model. The function returns the tuned parameters. You can use the same function by adjusting it for your best model. The candiate hyperparameters to be tuned can be obtained by calling `help` funciton in Python. For this specific example, you can call `help(DecisionTreeClassifier)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "def grid_search(X, y, kfolds):\n",
    "    \n",
    "    #create a dictionary of all values we want to test\n",
    "    param_grid = {'criterion':['gini','entropy'], 'max_depth': np.arange(3, 15)}\n",
    "    # decision tree model\n",
    "    dtree_model=DecisionTreeClassifier()\n",
    "    #use gridsearch to test all values\n",
    "    dtree_gscv = GridSearchCV(dtree_model, param_grid, cv=kfolds)\n",
    "    #fit model to data\n",
    "    dtree_gscv.fit(X, y)\n",
    "    return dtree_gscv.best_params_\n",
    "\n",
    "grid_search(X = features_train, y = response_train, kfolds = 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
